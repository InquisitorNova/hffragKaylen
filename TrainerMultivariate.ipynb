{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_30629/1043725938.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#from wandb.keras import WandbCallback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/seaborn/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Import seaborn objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mrcmod\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa: F401,F403\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa: F401,F403\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpalettes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa: F401,F403\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mrelational\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa: F401,F403\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/seaborn/rcmod.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmpl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcycler\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcycler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpalettes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/seaborn/palettes.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mexternal\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mhusl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdesaturate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_color_cycle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcolors\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mxkcd_rgb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcrayons\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/seaborn/utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmpl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolors\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmplcol\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# numpy compat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m from pandas.compat import (\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mnp_version_under1p18\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_np_version_under1p18\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mis_numpy_dev\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_is_numpy_dev\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/compat/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_typing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m from pandas.compat.numpy import (\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mis_numpy_dev\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mnp_array_datetime64_compat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/compat/numpy/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVersion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# numpy versioning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/util/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m from pandas.util._decorators import (  # noqa\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mAppender\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mSubstitution\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mcache_readonly\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m )\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_libs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproperties\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcache_readonly\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_typing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/_libs/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_libs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterval\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInterval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m from pandas._libs.tslibs import (\n\u001b[1;32m     15\u001b[0m     \u001b[0mNaT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/SpocFit/lib/python3.9/importlib/_bootstrap.py\u001b[0m in \u001b[0;36mparent\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import wandb\n",
    "#from wandb.keras import WandbCallback\n",
    "from keras import callbacks\n",
    "import keras\n",
    "import DeepSetNeuralNetArchitecture as DSNNA\n",
    "import ParticleTransformer as ParT\n",
    "from hffragDeepSetsMultivariate import PredictOnEpoch\n",
    "from DeepSetNeuralNetArchitecture import LogNormal_Loss_Function\n",
    "from DeepSetNeuralNetArchitecture import Mean_Squared_Error\n",
    "from hffragDeepSetsMultivariate import hffragDeepSets\n",
    "from HffragDeepSetsProjection import DeepSetsProjection\n",
    "from hffragDeepSetsMultivariate import Multivariate_Gaussian_Negative_Likelihood_Loss_Curve\n",
    "import keras.backend as k\n",
    "import uproot\n",
    "import awkward as ak\n",
    "import sklearn as sk\n",
    "from numpy.lib.recfunctions import structured_to_unstructured\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "from hffrag import fixedbinning\n",
    "from hffrag import binneddensity\n",
    "import numpy_indexed as npi\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from timeit import default_timer as timer\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"default\")\n",
    "plt.rcParams['axes.facecolor'] = 'white'\n",
    "plt.rcParams['savefig.facecolor'] = 'white'\n",
    "plt.rc('text',usetex = False)\n",
    "plt.rc('font',family = 'Times New Roman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data is being stored in a tree datastructure.\n",
    "# We access the charm root using this command\n",
    "tree = uproot.open(\"hffrag.root:CharmAnalysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial parameters\n",
    "MASKVAL = -999 # This value is introduced to ensure arrays are regular (Of the same size). They will be masked later by the network\n",
    "MAXTRACKS = 32 # This value is the maximum number of tracks allowed per event\n",
    "BATCHSIZE = 64 # This is the batch size of the mini batches used during training\n",
    "EPOCHS = 1000 # This is the default number of epochs for which the neural network will train providing that early stopping does not occur\n",
    "MAXEVENTS = 1e20 #This is the maximum number of events that will the program will accept\n",
    "LR = 1e-4 #This is the default learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the features we wish to study\n",
    "track_features = [\"AnalysisTracks_pt\", \"AnalysisTracks_eta\", \"AnalysisTracks_phi\", \"AnalysisTracks_z0sinTheta\",\n",
    "                  \"AnalysisTracks_d0sig\", \"AnalysisTracks_d0\", \"AnalysisTracks_d0sigPV\", \"AnalysisTracks_d0PV\"]\n",
    "jet_features = [\"AnalysisAntiKt4TruthJets_pt\", \"AnalysisAntiKt4TruthJets_eta\", \"AnalysisAntiKt4TruthJets_phi\",\n",
    "                \"AnalysisAntiKt4TruthJets_ghostB_pt\", \"AnalysisAntiKt4TruthJets_ghostB_eta\",\"AnalysisAntiKt4TruthJets_ghostB_phi\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the dat from the root file\n",
    "features = tree.arrays(jet_features+track_features, entry_stop=MAXEVENTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the events of interest\n",
    "events = features[ak.sum(\n",
    "    features[\"AnalysisAntiKt4TruthJets_pt\"] > 25000, axis=1) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of jets to train on is:  141329\n",
      "The number of track features is:  8\n"
     ]
    }
   ],
   "source": [
    "# Displays the number of jets being trained on\n",
    "jets = events[jet_features][:, 0]\n",
    "print(\"The number of jets to train on is: \", len(jets))\n",
    "print(\"The number of track features is: \",len(track_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select tracks from the events\n",
    "tracks = events[track_features]\n",
    "\n",
    "# Match the tracks to the jets\n",
    "matchedtracks = tracks[DSNNA.Match_Tracks(jets, tracks)]\n",
    "\n",
    "# Pad and Flatten the data\n",
    "matchedtracks = DSNNA.flatten(matchedtracks, MAXTRACKS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3 outputs\n",
      "There are 32 inputs\n"
     ]
    }
   ],
   "source": [
    "# Identify the the bottom jets and their associated tracks\n",
    "bjets = ak.sum(jets[\"AnalysisAntiKt4TruthJets_ghostB_pt\"] > 5000, axis=1) > 0\n",
    "jets = jets[bjets]\n",
    "\n",
    "# Obtain the pt, eta and phi of each b hadron jet\n",
    "bhads_pt = jets[\"AnalysisAntiKt4TruthJets_ghostB_pt\"][:, 0].to_numpy()\n",
    "bhads_eta = jets[\"AnalysisAntiKt4TruthJets_ghostB_eta\"][:,0].to_numpy()\n",
    "bhads_phi = jets[\"AnalysisAntiKt4TruthJets_ghostB_phi\"][:,0].to_numpy()\n",
    "\n",
    "jets_pt = jets[\"AnalysisAntiKt4TruthJets_pt\"].to_numpy()\n",
    "jets_eta = jets[\"AnalysisAntiKt4TruthJets_eta\"].to_numpy()\n",
    "jets_phi = jets[\"AnalysisAntiKt4TruthJets_phi\"].to_numpy()\n",
    "b_jets = np.stack([jets_pt,jets_eta,jets_phi], axis = -1)\n",
    "\n",
    "bhads = np.stack([bhads_pt,bhads_eta,bhads_phi],axis = -1) #Combine the momentum, eta and phi for each jet into one array\n",
    "\n",
    "print(\"There are {} outputs\".format(np.shape(bhads)[1])) # Display the number of target features the neural network will predict\n",
    "matchedtracks = matchedtracks[bjets]\n",
    "print(\"There are {} inputs\".format(np.shape(matchedtracks)[1])) # Display the number of target features the neural network will use in it's ppredictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the jet and tracks to unstructed data.\n",
    "jets = structured_to_unstructured(jets[jet_features[:-3]])\n",
    "matchedtracks = structured_to_unstructured(matchedtracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/physics/phujdj/DeepLearningParticlePhysics/DeepSetNeuralNetArchitecture.py:104: RuntimeWarning: overflow encountered in sinh\n",
      "  pzs = np.where(mask1 | mask3, pts, pts * np.sinh(etas))\n"
     ]
    }
   ],
   "source": [
    "# Convert the coordinates of the b jets and tracks to cartesian coordinates\n",
    "tracks_p = DSNNA.pt_eta_phi_2_px_py_pz_tracks(matchedtracks.to_numpy())\n",
    "bhads = DSNNA.pt_eta_phi_2_px_py_pz_jets(bhads)\n",
    "b_jets = DSNNA.pt_eta_phi_2_px_py_pz_jets(b_jets)\n",
    "\n",
    "#Combine the momenta of the tracks with the rest of the track features to form the track dataset\n",
    "tracks = np.concatenate([tracks_p,matchedtracks[:,:,3:].to_numpy()],axis = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(68143,)\n",
      "(68143, 3)\n",
      "[0.92818976 0.92693198 0.92622171]\n",
      "0.928189759678061\n",
      "-1196.4922484782348 373.05142412393263\n",
      "0.928189759678061\n",
      "0.928189759678061\n",
      "-230.22990301009094 171.10816219196536\n"
     ]
    }
   ],
   "source": [
    "b_jets_mag = np.linalg.norm(b_jets, axis = 1)\n",
    "\n",
    "bhads_fractions_px = bhads[:,0]/b_jets[:,0]\n",
    "bhads_fractions_py = bhads[:,1]/b_jets[:,1]\n",
    "bhads_fractions_pz = bhads[:,2]/b_jets[:,2]\n",
    "print(bhads_fractions_px.shape)\n",
    "\n",
    "bhads_fractions = np.stack([bhads_fractions_px,bhads_fractions_py, bhads_fractions_pz], axis = -1)\n",
    "print(bhads_fractions.shape)\n",
    "\n",
    "print(bhads_fractions[0])\n",
    "print(bhads[0,0]/b_jets[0,0])\n",
    "print(np.min(bhads_fractions),np.max(bhads_fractions))\n",
    "\n",
    "print(bhads_fractions_px[0])\n",
    "print(bhads[0,0]/b_jets[0,0])\n",
    "print(np.min(bhads_fractions_px),np.max(bhads_fractions_px))\n",
    "\n",
    "sum_px_tracks = np.sum(tracks[:,:,0], axis = 1)\n",
    "sum_py_tracks = np.sum(tracks[:,:,1], axis = 1)\n",
    "sum_pz_tracks = np.sum(tracks[:,:,2], axis = 1)\n",
    "\n",
    "bhads_projection = ((bhads*b_jets).sum(axis = 1))/(b_jets_mag**2)\n",
    "\n",
    "b_jets = np.stack([b_jets[:,0], b_jets[:,1], b_jets[:,2], sum_px_tracks, sum_py_tracks, sum_pz_tracks], axis = -1)\n",
    "bhads_targets = np.stack([bhads_fractions_px,bhads_fractions_py, bhads_fractions_pz, bhads_projection], axis = -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(68143, 32, 3)\n",
      "(68143, 32, 3)\n",
      "0.11796763971634215\n",
      "0.032278004649905545 6.120054830548441\n",
      "(68143, 32)\n"
     ]
    }
   ],
   "source": [
    "tracks_fractions_px = tracks[:,:,0]/b_jets[:,0,np.newaxis]\n",
    "tracks_fractions_py = tracks[:,:,1]/b_jets[:,1,np.newaxis]\n",
    "tracks_fractions_pz = tracks[:,:,2]/b_jets[:,2,np.newaxis]\n",
    "\n",
    "Track_fractions = np.stack([tracks_fractions_px,tracks_fractions_py, tracks_fractions_pz], axis = -1)\n",
    "print(Track_fractions.shape)\n",
    "\n",
    "print(Track_fractions.shape)\n",
    "print(tracks[0,0,0]/b_jets[0,0])\n",
    "print(np.mean(Track_fractions),np.std(Track_fractions))\n",
    "\n",
    "Tracks_projection = ((tracks[:,:,:3]*b_jets[:,np.newaxis,:3]).sum(axis = 2)/(b_jets_mag[:,np.newaxis]**2))\n",
    "print(Tracks_projection.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(68143, 32, 8)\n",
      "[0.26189855 0.38175348 0.10230412 1.42959932 1.58783932 1.42992229\n",
      " 1.60955267 1.42990682]\n",
      "(68143, 6)\n",
      "[0.60802015 1.59589996 0.53448783 0.11311969 0.27945027 0.08234729]\n"
     ]
    }
   ],
   "source": [
    "Scaler_tracks = StandardScaler()\n",
    "Num_events,Num_tracks,Num_features = np.shape(tracks)\n",
    "Scaled_tracks = np.reshape(tracks, newshape=(-1,Num_features))\n",
    "tracks_scaled = Scaler_tracks.fit_transform(Scaled_tracks)\n",
    "tracks_scaled = np.reshape(tracks_scaled, newshape= (Num_events,Num_tracks,Num_features))\n",
    "print(np.shape(tracks_scaled))\n",
    "print(tracks_scaled[0,0,:])\n",
    "\n",
    "Scaler_jets = StandardScaler()\n",
    "Num_events,Num_features = np.shape(b_jets)\n",
    "b_jets_scaled = np.reshape(b_jets, newshape=(-1,Num_features))\n",
    "b_jets_scaled = Scaler_jets.fit_transform(b_jets)\n",
    "b_jets_scaled = np.reshape(b_jets_scaled, newshape= (Num_events,Num_features))\n",
    "print(np.shape(b_jets_scaled))\n",
    "print(b_jets_scaled[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(68143, 32, 11)\n"
     ]
    }
   ],
   "source": [
    "Tracks_input = np.concatenate([tracks_scaled, Track_fractions], axis = -1)\n",
    "print(Tracks_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(68143, 38)\n"
     ]
    }
   ],
   "source": [
    "b_jets_input = np.concatenate([b_jets_scaled, Tracks_projection], axis = -1)\n",
    "print(b_jets_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and validation sets.\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    Tracks_input, bhads_targets, train_size=0.7, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and validation sets.\n",
    "X_train_b_jets, X_valid_b_jets, y_train_b_jets, y_valid_b_jets = train_test_split(\n",
    "    b_jets_input, bhads_targets, train_size=0.7, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47700, 32, 11) (47700, 4)\n",
      "(1, 32, 11) (1, 4)\n"
     ]
    }
   ],
   "source": [
    "X_train_event, y_train_event = np.array([X_train[0]]), np.array([y_train[0]])\n",
    "X_valid_event, y_valid_event = np.array([X_valid[0]]), np.array([y_valid[0]])\n",
    "print(np.shape(X_train),np.shape(y_train))\n",
    "print(np.shape(X_train_event),np.shape(y_train_event))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47700, 32, 11) (20443, 32, 11)\n",
      "(47700, 38) (20443, 38)\n",
      "(47700, 4) (20443, 4)\n"
     ]
    }
   ],
   "source": [
    "#Check for the of the training and validation sets\n",
    "print(np.shape(X_train), np.shape(X_valid))\n",
    "print(np.shape(X_train_b_jets), np.shape(X_valid_b_jets))\n",
    "print(np.shape(y_train), np.shape(y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(Tracks_input)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 100, 100, 100, 100, 100, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-04 20:29:51.671539: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-02-04 20:29:51.671571: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-02-04 20:29:51.671595: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (vonneumann.csc.warwick.ac.uk): /proc/driver/nvidia/version does not exist\n",
      "2023-02-04 20:29:51.673235: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "#Cyclical Learning Rate Scheduler:\n",
    "steps_per_epoch = len(X_train)\n",
    "clr = tfa.optimizers.CyclicalLearningRate(initial_learning_rate = 1e-4,\n",
    "maximal_learning_rate = 0.01,\n",
    "scale_fn = lambda x: 1/(2**(x-1)),\n",
    "step_size = 2.0 * steps_per_epoch\n",
    ")\n",
    "class TimingCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, logs = {}):\n",
    "        self.logs = []\n",
    "    def on_epoch_begin(self, epoch, logs ={}):\n",
    "        self.starttime = timer()\n",
    "    def on_epoch_end(self, epoch, logs = {}):\n",
    "        self.logs.append(timer() - self.starttime)\n",
    "        \n",
    "# Builds the deep neural network\n",
    "track_layers = [100 for x in range(3)]\n",
    "jet_layers = [100 for x in range(3)]\n",
    "b_jets_layers = [100 for x in range(3)]\n",
    "\n",
    "len1 = [len(track_features)]+track_layers\n",
    "print(len1)\n",
    "\n",
    "#Initializers the optimizer used for training the network\n",
    "optimizer = tf.keras.optimizers.Nadam(LR)\n",
    "\n",
    "#Build a DeepSets Projection Neural Network\n",
    "DeepSetProjector = DeepSetsProjection([np.shape(Tracks_input)[2]]+track_layers, jet_layers, b_jets_layers, np.shape(y_train)[1], 0.0001, np.shape(b_jets_input)[1],optimizer, loss_curve=tf.keras.losses.MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)           [(None, 38)]         0           []                               \n",
      "                                                                                                  \n",
      " dense_19 (Dense)               (None, 100)          3900        ['input_4[0][0]']                \n",
      "                                                                                                  \n",
      " input_3 (InputLayer)           [(None, None, 11)]   0           []                               \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)            (None, 100)          0           ['dense_19[1][0]']               \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, None, 11)     132         ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " layer_normalization_6 (LayerNo  (None, 100)         200         ['dropout_6[1][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " time_distributed_residual_unit  (None, None, 11)    286         ['dense[1][0]']                  \n",
      " s (TimeDistributedResidualUnit                                                                   \n",
      " s)                                                                                               \n",
      "                                                                                                  \n",
      " dense_20 (Dense)               (None, 100)          10100       ['layer_normalization_6[1][0]']  \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, None, 100)    1200        ['time_distributed_residual_units\n",
      "                                                                 [1][0]']                         \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)            (None, 100)          0           ['dense_20[1][0]']               \n",
      "                                                                                                  \n",
      " time_distributed_residual_unit  (None, None, 100)   20400       ['dense_3[1][0]']                \n",
      " s_1 (TimeDistributedResidualUn                                                                   \n",
      " its)                                                                                             \n",
      "                                                                                                  \n",
      " layer_normalization_7 (LayerNo  (None, 100)         200         ['dropout_7[1][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, None, 100)    10100       ['time_distributed_residual_units\n",
      "                                                                 _1[1][0]']                       \n",
      "                                                                                                  \n",
      " dense_21 (Dense)               (None, 100)          10100       ['layer_normalization_7[1][0]']  \n",
      "                                                                                                  \n",
      " time_distributed_residual_unit  (None, None, 100)   20400       ['dense_6[1][0]']                \n",
      " s_2 (TimeDistributedResidualUn                                                                   \n",
      " its)                                                                                             \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)            (None, 100)          0           ['dense_21[1][0]']               \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, None, 100)    10100       ['time_distributed_residual_units\n",
      "                                                                 _2[1][0]']                       \n",
      "                                                                                                  \n",
      " layer_normalization_8 (LayerNo  (None, 100)         200         ['dropout_8[1][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " time_distributed_residual_unit  (None, None, 100)   20400       ['dense_9[1][0]']                \n",
      " s_3 (TimeDistributedResidualUn                                                                   \n",
      " its)                                                                                             \n",
      "                                                                                                  \n",
      " dense_22 (Dense)               (None, 100)          10100       ['layer_normalization_8[1][0]']  \n",
      "                                                                                                  \n",
      " dense_12 (Dense)               (None, None, 100)    10100       ['time_distributed_residual_units\n",
      "                                                                 _3[1][0]']                       \n",
      "                                                                                                  \n",
      " dropout_9 (Dropout)            (None, 100)          0           ['dense_22[1][0]']               \n",
      "                                                                                                  \n",
      " time_distributed_residual_unit  (None, None, 100)   20400       ['dense_12[1][0]']               \n",
      " s_4 (TimeDistributedResidualUn                                                                   \n",
      " its)                                                                                             \n",
      "                                                                                                  \n",
      " layer_normalization_9 (LayerNo  (None, 100)         200         ['dropout_9[1][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_15 (Dense)               (None, None, 100)    10100       ['time_distributed_residual_units\n",
      "                                                                 _4[1][0]']                       \n",
      "                                                                                                  \n",
      " dense_23 (Dense)               (None, 100)          10100       ['layer_normalization_9[1][0]']  \n",
      "                                                                                                  \n",
      " time_distributed_residual_unit  (None, None, 100)   20400       ['dense_15[1][0]']               \n",
      " s_5 (TimeDistributedResidualUn                                                                   \n",
      " its)                                                                                             \n",
      "                                                                                                  \n",
      " dropout_10 (Dropout)           (None, 100)          0           ['dense_23[1][0]']               \n",
      "                                                                                                  \n",
      " time_distributed_12 (TimeDistr  (None, None, 100)   10100       ['time_distributed_residual_units\n",
      " ibuted)                                                         _5[1][0]']                       \n",
      "                                                                                                  \n",
      " layer_normalization_10 (LayerN  (None, 100)         200         ['dropout_10[1][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " sum (Sum)                      (None, 100)          0           ['time_distributed_12[1][0]']    \n",
      "                                                                                                  \n",
      " dense_24 (Dense)               (None, 100)          10100       ['layer_normalization_10[1][0]'] \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 200)          0           ['sum[1][0]',                    \n",
      "                                                                  'dense_24[1][0]']               \n",
      "                                                                                                  \n",
      " dense_25 (Dense)               (None, 100)          20100       ['concatenate[1][0]']            \n",
      "                                                                                                  \n",
      " residual_units (ResidualUnits)  (None, 100)         20400       ['dense_25[1][0]']               \n",
      "                                                                                                  \n",
      " dense_28 (Dense)               (None, 100)          10100       ['residual_units[1][0]']         \n",
      "                                                                                                  \n",
      " residual_units_1 (ResidualUnit  (None, 100)         20400       ['dense_28[1][0]']               \n",
      " s)                                                                                               \n",
      "                                                                                                  \n",
      " dense_31 (Dense)               (None, 100)          10100       ['residual_units_1[1][0]']       \n",
      "                                                                                                  \n",
      " residual_units_2 (ResidualUnit  (None, 100)         20400       ['dense_31[1][0]']               \n",
      " s)                                                                                               \n",
      "                                                                                                  \n",
      " dense_34 (Dense)               (None, 100)          10100       ['residual_units_2[1][0]']       \n",
      "                                                                                                  \n",
      " residual_units_3 (ResidualUnit  (None, 100)         20400       ['dense_34[1][0]']               \n",
      " s)                                                                                               \n",
      "                                                                                                  \n",
      " dense_37 (Dense)               (None, 100)          10100       ['residual_units_3[1][0]']       \n",
      "                                                                                                  \n",
      " residual_units_4 (ResidualUnit  (None, 100)         20400       ['dense_37[1][0]']               \n",
      " s)                                                                                               \n",
      "                                                                                                  \n",
      " dense_40 (Dense)               (None, 4)            404         ['residual_units_4[1][0]']       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 372,422\n",
      "Trainable params: 372,422\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Summarises the DeepSetsProjector Set Neural Network Architecture\n",
    "DeepSetProjector.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introduce early_stopping to prevent overfitting\n",
    "early_stopping = callbacks.EarlyStopping(\n",
    "    min_delta=0.00001,  # The minimum amount of change to count as an improvement\n",
    "    patience=20,  # The number of epochs to wait before stopping\n",
    "    restore_best_weights=True,  # Keep the best weights\n",
    ")\n",
    "# Prevent spikes in the validation and training loss due to the gradient descent kicking the network out of a local minima\n",
    "reduce_learn_on_plateau = callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss', factor=0.80, patience=5, min_lr=1e-9)\n",
    "\n",
    "# Save the weights of the model to allow reuse in future.\n",
    "path = \"/home/physics/phujdj/DeepLearningParticlePhysics/CheckPointsDeepNet/DeepNetWeights&Biases.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(path)\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=path,\n",
    "                                                 save_weights_only=True, verbose=0, save_freq = 100*BATCHSIZE)\n",
    "#Timer\n",
    "cb = TimingCallback()\n",
    "\n",
    "#Weight&Biases Callback:\n",
    "#Wanda = WandbCallback(save_graph = True,save_weights_only = True, log_weights = True, log_gradients = True, log_evaluation = True, training_data = (X_train,y_train), validation_data = (X_valid,y_valid), log_batch_frequency = 5)\n",
    "\n",
    "# Learning Scheduler:\n",
    "exponential_decay_fn = DSNNA.expontial_decay(lr0 = LR,s = 30)\n",
    "learning_scheduler = tf.keras.callbacks.LearningRateScheduler(exponential_decay_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47700, 32, 11)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-04 20:30:08.397635: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x7f23040e6aa0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2023-02-04 20:30:08.397677: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): Host, Default Version\n",
      "2023-02-04 20:30:09.100298: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-02-04 20:30:09.114420: W tensorflow/compiler/tf2xla/kernels/random_ops.cc:57] Warning: Using tf.random.uniform with XLA compilation will ignore seeds; consider using tf.random.stateless_uniform instead if reproducible behavior is desired. model/dropout_6/dropout/random_uniform/RandomUniform\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  3/746 [..............................] - ETA: 23s - loss: 12.6705    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-04 20:30:32.243843: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "746/746 [==============================] - 92s 71ms/step - loss: 17.9475 - val_loss: 7.7062 - lr: 1.0000e-04\n",
      "Epoch 2/1000\n",
      "746/746 [==============================] - 25s 33ms/step - loss: 14.1376 - val_loss: 5.0285 - lr: 1.0000e-04\n",
      "Epoch 3/1000\n",
      "321/746 [===========>..................] - ETA: 12s - loss: 4.2464"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_12892/3959353358.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m history  = DeepSetProjector.fit(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train_b_jets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_valid_b_jets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBATCHSIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/SpocFit/lib/python3.9/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/SpocFit/lib/python3.9/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1648\u001b[0m                         ):\n\u001b[1;32m   1649\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1650\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1651\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1652\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/SpocFit/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/SpocFit/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/SpocFit/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 919\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    920\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    921\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m~/anaconda3/envs/SpocFit/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    132\u001b[0m       (concrete_function,\n\u001b[1;32m    133\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 134\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    135\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/SpocFit/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1743\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1745\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1746\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/anaconda3/envs/SpocFit/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    376\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    379\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/SpocFit/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history  = DeepSetProjector.fit(\n",
    "    (X_train, X_train_b_jets), y_train,\n",
    "    validation_data = ((X_valid,X_valid_b_jets), y_valid),\n",
    "    epochs = 1000,\n",
    "    batch_size = BATCHSIZE,\n",
    "    callbacks = [early_stopping, cp_callback, cb, reduce_learn_on_plateau],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the loss and validation curves vs epoch\n",
    "history_df = pd.DataFrame(history.history)\n",
    "np.log(history_df.loc[:, [\"loss\",\"val_loss\"]]).plot()\n",
    "history_df.to_csv('/home/physics/phujdj/DeepLearningParticlePhysics/history.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output to the console the minimum epoch\n",
    "print(\"Minimum validation loss: {}\".format(history_df[\"loss\"].min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate the entire performance of the model\n",
    "loss = DeepSetProjector.evaluate((Tracks_input,b_jets_input),bhads_targets,verbose = 2)\n",
    "print(\"The Loaded DeepNet has loss: \", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Predictions = DeepSetProjector.predict((Tracks_input, b_jets_input))\n",
    "Predictions_px = Predictions[:,0] * b_jets[:,0]\n",
    "Predictions_py = Predictions[:,1] * b_jets[:,1]\n",
    "Predictions_pz = Predictions[:,2] * b_jets[:,2]\n",
    "Predictions_Projected = Predictions[:,3]\n",
    "print(Predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Error_px = bhads[:,0] - Predictions_px\n",
    "Pull_bhads_px = Error_px/np.std(bhads[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Error_py = bhads[:,1] - Predictions_py\n",
    "Pull_bhads_py = Error_py/np.std(bhads[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Error_pz = bhads[:,2] - Predictions_pz\n",
    "Pull_bhads_pz = Error_pz/np.std(bhads[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Error_projection = bhads_targets[:,-1] - Predictions_Projected\n",
    "Pull_bhads_pz = Error_pz/np.std(bhads_targets[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(Error_px))\n",
    "print(np.std(Error_px))\n",
    "binneddensity(Error_px, fixedbinning(-40000,40000,100),xlabel = \"Error_px\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(Error_py))\n",
    "print(np.std(Error_py))\n",
    "binneddensity(Error_py, fixedbinning(-40000,40000,100),xlabel = \"Error_py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(Error_pz))\n",
    "print(np.std(Error_pz))\n",
    "binneddensity(Error_pz, fixedbinning(-40000,40000,100),xlabel = \"Error_pz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(Error_projection))\n",
    "print(np.std(Error_projection))\n",
    "binneddensity(Error_projection, fixedbinning(-1,1,100),xlabel = \"Error_projection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(Pull_bhads_px))\n",
    "print(np.std(Pull_bhads_px))\n",
    "binneddensity(Pull_bhads_px, fixedbinning(-1,1,100),xlabel = \"Pull_px\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(Pull_bhads_py))\n",
    "print(np.std(Pull_bhads_py))\n",
    "binneddensity(Pull_bhads_py, fixedbinning(-1,1,100),xlabel = \"Pull_py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(Pull_bhads_pz))\n",
    "print(np.std(Pull_bhads_pz))\n",
    "binneddensity(Pull_bhads_pz, fixedbinning(-100000,100000,100),xlabel = \"Pull_pz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize = (12,12))\n",
    "sns.scatterplot(\n",
    "    y = Predictions_px,\n",
    "    x = bhads[:,0],\n",
    "    color = \"blue\"\n",
    ")\n",
    "ax.set_xlim([-400000,400000])\n",
    "ax.set_ylim([-400000,400000])\n",
    "ax.set_title(\"Scatterplot of the true vs pred X momenta\")\n",
    "ax.set_xlabel(\"The true X momenta of the tracks from each event\")\n",
    "ax.set_ylabel(\"The predicted X momenta of b hadron jets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize = (12,12))\n",
    "sns.scatterplot(\n",
    "    y = Predictions_py,\n",
    "    x = bhads[:,1],\n",
    "    color = \"green\"\n",
    ")\n",
    "ax.set_xlim([-400000,400000])\n",
    "ax.set_ylim([-400000,400000])\n",
    "ax.set_title(\"Scatterplot of the true vs pred Y momenta\")\n",
    "ax.set_xlabel(\"The true Y momenta of the tracks from each event\")\n",
    "ax.set_ylabel(\"The predicted Y momenta of b hadron jets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize = (12,12))\n",
    "sns.scatterplot(\n",
    "    y = Predictions_pz,\n",
    "    x = bhads[:,2],\n",
    "    color = \"orange\"\n",
    ")\n",
    "ax.set_title(\"Scatterplot of the true vs pred Z momenta\")\n",
    "ax.set_xlabel(\"The true Z momenta of the tracks from each event\")\n",
    "ax.set_ylabel(\"The predicted Z momenta of b hadron jets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Predictions_cart = np.stack([Predictions_px, Predictions_py, Predictions_pz], axis = -1)\n",
    "Predictions_Projection = ((Predictions_cart*b_jets[:,:3]).sum(axis = 1))/(b_jets_mag**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize = (12,12))\n",
    "sns.scatterplot(\n",
    "    y = Predictions_Projection,\n",
    "    x = bhads_projection,\n",
    "    color = \"orange\"\n",
    ")\n",
    "ax.set_title(\"Scatterplot of the true vs pred Z momenta\")\n",
    "ax.set_xlabel(\"The true Z momenta of the tracks from each event\")\n",
    "ax.set_ylabel(\"The predicted Z momenta of b hadron jets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(Predictions_Projection))\n",
    "print(np.std(Predictions_Projection))\n",
    "binneddensity(Predictions_Projection, fixedbinning(0,2,100),xlabel = \"Plot\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a05ddcd8ffea9a6a7d2e914b733df5445b717626b5b8c92c04bfc4eb6e7f5cba"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
