{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "from keras import callbacks\n",
    "import keras\n",
    "import DeepSetNeuralNetArchitecture as DSNNA\n",
    "import ParticleTransformer as ParT\n",
    "from DeepSetNeuralNetArchitecture import PredictOnEpoch\n",
    "import ConvolutionalRecurrentNeuralNetworkArchitecture as CRNNA\n",
    "from DeepSetNeuralNetArchitecture import LogNormal_Loss_Function\n",
    "from DeepSetNeuralNetArchitecture import Mean_Squared_Error\n",
    "import keras.backend as k\n",
    "import uproot\n",
    "import awkward as ak\n",
    "import sklearn as sk\n",
    "from numpy.lib.recfunctions import structured_to_unstructured\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "from hffrag import fixedbinning\n",
    "from hffrag import binneddensity\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from timeit import default_timer as timer\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "wandb.init(project = \"hffrag-ParticleTransformerNeuralNetworkArchitecture\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data is being stored in a tree datastructure.\n",
    "# We access the charm root using this command\n",
    "tree = uproot.open(\"hffrag.root:CharmAnalysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial parameters\n",
    "MASKVAL = -999 # This value is introduced to ensure arrays are regular (Of the same size). They will be masked later by the network\n",
    "MAXTRACKS = 32 # This value is the maximum number of tracks allowed per event\n",
    "BATCHSIZE = 64 # This is the batch size of the mini batches used during training\n",
    "EPOCHS = 100 # This is the default number of epochs for which the neural network will train providing that early stopping does not occur\n",
    "MAXEVENTS = 1e20 #This is the maximum number of events that will the program will accept\n",
    "LR = 1e-4 #This is the default learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.config = {\n",
    "    \"learning_rate\": LR,\n",
    "    \"epochs\":EPOCHS,\n",
    "    \"batch_size\":BATCHSIZE,\n",
    "    \"max_events\": MAXEVENTS,\n",
    "    \"MAXTRACKS\": MAXTRACKS, \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the features we wish to study\n",
    "track_features = [\"AnalysisTracks_pt\", \"AnalysisTracks_eta\", \"AnalysisTracks_phi\", \"AnalysisTracks_z0sinTheta\",\n",
    "                  \"AnalysisTracks_d0sig\", \"AnalysisTracks_d0\", \"AnalysisTracks_d0sigPV\", \"AnalysisTracks_d0PV\"]\n",
    "jet_features = [\"AnalysisAntiKt4TruthJets_pt\", \"AnalysisAntiKt4TruthJets_eta\", \"AnalysisAntiKt4TruthJets_phi\",\n",
    "                \"AnalysisAntiKt4TruthJets_ghostB_pt\", \"AnalysisAntiKt4TruthJets_ghostB_eta\",\"AnalysisAntiKt4TruthJets_ghostB_phi\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the dat from the root file\n",
    "features = tree.arrays(jet_features+track_features, entry_stop=MAXEVENTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the events of interest\n",
    "events = features[ak.sum(\n",
    "    features[\"AnalysisAntiKt4TruthJets_pt\"] > 25000, axis=1) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of jets to train on is:  141329\n",
      "The number of track features is:  8\n"
     ]
    }
   ],
   "source": [
    "# Displays the number of jets being trained on\n",
    "jets = events[jet_features][:, 0]\n",
    "print(\"The number of jets to train on is: \", len(jets))\n",
    "print(\"The number of track features is: \",len(track_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select tracks from the events\n",
    "tracks = events[track_features]\n",
    "\n",
    "# Match the tracks to the jets\n",
    "matchedtracks = tracks[DSNNA.Match_Tracks(jets, tracks)]\n",
    "\n",
    "# Pad and Flatten the data\n",
    "matchedtracks = DSNNA.flatten(matchedtracks, MAXTRACKS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3 outputs\n",
      "There are 32 inputs\n"
     ]
    }
   ],
   "source": [
    "# Identify the the bottom jets and their associated tracks\n",
    "bjets = ak.sum(jets[\"AnalysisAntiKt4TruthJets_ghostB_pt\"] > 5000, axis=1) > 0\n",
    "jets = jets[bjets]\n",
    "\n",
    "# Obtain the pt, eta and phi of each b hadron jet\n",
    "bhads_pt = jets[\"AnalysisAntiKt4TruthJets_ghostB_pt\"][:, 0].to_numpy()\n",
    "bhads_eta = jets[\"AnalysisAntiKt4TruthJets_ghostB_eta\"][:,0].to_numpy()\n",
    "bhads_phi = jets[\"AnalysisAntiKt4TruthJets_ghostB_phi\"][:,0].to_numpy()\n",
    "\n",
    "bhads = np.stack([bhads_pt,bhads_eta,bhads_phi],axis = -1) #Combine the momentum, eta and phi for each jet into one array\n",
    "\n",
    "print(\"There are {} outputs\".format(np.shape(bhads)[1])) # Display the number of target features the neural network will predict\n",
    "matchedtracks = matchedtracks[bjets]\n",
    "print(\"There are {} inputs\".format(np.shape(matchedtracks)[1])) # Display the number of target features the neural network will use in it's ppredictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(68143, 3)\n"
     ]
    }
   ],
   "source": [
    "# Transform the jet and tracks to unstructed data.\n",
    "jets = structured_to_unstructured(jets[jet_features[:-3]])\n",
    "matchedtracks = structured_to_unstructured(matchedtracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(68143, 32, 3)\n",
      "(68143, 32, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/physics/phujdj/DeepLearningParticlePhysics/DeepSetNeuralNetArchitecture.py:103: RuntimeWarning: overflow encountered in sinh\n",
      "  pzs = np.where(mask1 | mask3, pts, pts * np.sinh(etas))\n"
     ]
    }
   ],
   "source": [
    "# Convert the coordinates of the b jets and tracks to cartesian coordinates\n",
    "tracks_p = DSNNA.pt_eta_phi_2_px_py_pz_tracks(matchedtracks.to_numpy())\n",
    "bhads = DSNNA.pt_eta_phi_2_px_py_pz_jets(bhads)\n",
    "\n",
    "#Combine the momenta of the tracks with the rest of the track features to form the track dataset\n",
    "tracks = np.concatenate([tracks_p,matchedtracks[:,:,3:].to_numpy()],axis = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(68143, 32, 8)\n",
      "[0.26189855 0.38175348 0.10230412 1.42959932 1.58783932 1.42992229\n",
      " 1.60955267 1.42990682]\n"
     ]
    }
   ],
   "source": [
    "Scaler = StandardScaler()\n",
    "Num_events,Num_tracks,Num_features = np.shape(tracks)\n",
    "tracks = np.reshape(tracks, newshape=(-1,Num_features))\n",
    "tracks = Scaler.fit_transform(tracks)\n",
    "tracks = np.reshape(tracks, newshape= (Num_events,Num_tracks,Num_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and validation sets.\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    tracks, bhads, train_size=0.8, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_event, y_train_event = np.array([X_train[0]]), np.array([y_train[0]])\n",
    "X_valid_event, y_valid_event = np.array([X_valid[0]]), np.array([y_valid[0]])\n",
    "print(np.shape(X_train),np.shape(y_train))\n",
    "print(np.shape(X_train_event),np.shape(y_train_event))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for the of the training and validation sets\n",
    "print(np.shape(X_train), np.shape(X_valid))\n",
    "print(np.shape(y_train), np.shape(y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the training and validation datasets.\n",
    "np.save(\"/home/physics/phujdj/DeepLearningParticlePhysics/TrainingAndValidationData/X_train_data.npy\",X_train)\n",
    "np.save(\"/home/physics/phujdj/DeepLearningParticlePhysics/TrainingAndValidationData/X_valid_data.npy\",X_valid)\n",
    "np.save(\"/home/physics/phujdj/DeepLearningParticlePhysics/TrainingAndValidationData/y_train_data.npy\",y_train)\n",
    "np.save(\"/home/physics/phujdj/DeepLearningParticlePhysics/TrainingAndValidationData/y_valid_data.npy\",y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 32, 32, 32, 32, 32]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-13 10:26:08.981221: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-01-13 10:26:08.981254: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-01-13 10:26:08.981273: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (vonneumann.csc.warwick.ac.uk): /proc/driver/nvidia/version does not exist\n",
      "2023-01-13 10:26:08.983204: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 100, 100, 100, 100]\n"
     ]
    }
   ],
   "source": [
    "#Cyclical Learning Rate Scheduler:\n",
    "steps_per_epoch = len(X_train)\n",
    "clr = tfa.optimizers.CyclicalLearningRate(initial_learning_rate = 1e-4,\n",
    "maximal_learning_rate = 0.01,\n",
    "scale_fn = lambda x: 1/(2**(x-1)),\n",
    "step_size = 2.0 * steps_per_epoch\n",
    ")\n",
    "class TimingCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, logs = {}):\n",
    "        self.logs = []\n",
    "    def on_epoch_begin(self, epoch, logs ={}):\n",
    "        self.starttime = timer()\n",
    "    def on_epoch_end(self, epoch, logs = {}):\n",
    "        self.logs.append(timer() - self.starttime)\n",
    "        \n",
    "# Builds the deep neural network\n",
    "track_layers = [64,64,64,64,64]\n",
    "jet_layers = [128,128,128,128,128]\n",
    "\n",
    "len1 = [len(track_features)]+track_layers\n",
    "print(len1)\n",
    "\n",
    "#Initializers the optimizer used for training the network\n",
    "optimizer = tf.keras.optimizers.Nadam(LR)\n",
    "optimizer_Constant = tf.keras.optimizers.SGD(learning_rate = 1e-4, momentum = 0.9, clipnorm = 1.0, nesterov = True )\n",
    "\n",
    "#Builds the DeepSet Neural Network\n",
    "DeepNet = DSNNA.DeepSetNeuralNetwork(\n",
    "    [len(track_features)] + track_layers, jet_layers,np.shape(y_train)[1],optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, None, 8)]         0         \n",
      "                                                                 \n",
      " masking (Masking)           (None, None, 8)           0         \n",
      "                                                                 \n",
      " time_distributed (TimeDistr  (None, None, 8)          72        \n",
      " ibuted)                                                         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, None, 8)          32        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " time_distributed_1 (TimeDis  (None, None, 32)         288       \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, None, 32)         128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " time_distributed_2 (TimeDis  (None, None, 32)         1056      \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, None, 32)         128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " time_distributed_3 (TimeDis  (None, None, 32)         1056      \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, None, 32)         128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " time_distributed_4 (TimeDis  (None, None, 32)         1056      \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, None, 32)         128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " time_distributed_5 (TimeDis  (None, None, 32)         1056      \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " sum (Sum)                   (None, 32)                0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 64)                2112      \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 64)               256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 64)               256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 64)               256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 64)               256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 64)               256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 9)                 585       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,745\n",
      "Trainable params: 24,833\n",
      "Non-trainable params: 912\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Summarises the Deep Set Neural Network Architecture\n",
    "DeepNet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#plot_model(DeepNet, to_file =\"NetworkArchitecture.png\", show_shapes = True, show_layer_names = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introduce early_stopping to prevent overfitting\n",
    "early_stopping = callbacks.EarlyStopping(\n",
    "    min_delta=0.00001,  # The minimum amount of change to count as an improvement\n",
    "    patience=30,  # The number of epochs to wait before stopping\n",
    "    restore_best_weights=True,  # Keep the best weights\n",
    ")\n",
    "# Prevent spikes in the validation and training loss due to the gradient descent kicking the network out of a local minima\n",
    "reduce_learn_on_plateau = callbacks.ReduceLROnPlateau(\n",
    "    monitor='loss', factor=0.80, patience=10, min_lr=1e-8)\n",
    "\n",
    "# Save the weights of the model to allow reuse in future.\n",
    "path = \"/home/physics/phujdj/DeepLearningParticlePhysics/CheckPointsDeepNet/DeepNetWeights&Biases.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(path)\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=path,\n",
    "                                                 save_weights_only=True, verbose=0, save_freq = 100*BATCHSIZE)\n",
    "#Timer\n",
    "cb = TimingCallback()\n",
    "\n",
    "#Weight&Biases Callback:\n",
    "Wanda = WandbCallback(save_graph = True,save_weights_only = True, log_weights = True, log_gradients = True, log_evaluation = True, training_data = (X_train,y_train), validation_data = (X_valid,y_valid), log_batch_frequency = 5)\n",
    "\n",
    "# Learning Scheduler:\n",
    "exponential_decay_fn = DSNNA.expontial_decay(lr0 = LR,s = 30)\n",
    "learning_scheduler = tf.keras.callbacks.LearningRateScheduler(exponential_decay_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-13 10:26:58.888435: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x7fcb380c1120 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2023-01-13 10:26:58.888478: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): Host, Default Version\n",
      "2023-01-13 10:26:59.124260: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 26/852 [..............................] - ETA: 3s - loss: 5266564710400.0000    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-13 10:27:03.737755: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1704/1704 [==============================] - 3s 1ms/step\n",
      "852/852 [==============================] - 24s 16ms/step - loss: 530744344576.0000 - val_loss: 86475973798070845440.0000 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "1704/1704 [==============================] - 2s 1ms/step\n",
      "852/852 [==============================] - 7s 8ms/step - loss: 74805829632.0000 - val_loss: 118445989613797376000.0000 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "1704/1704 [==============================] - 2s 1ms/step\n",
      "852/852 [==============================] - 7s 8ms/step - loss: 46472138752.0000 - val_loss: 3015390674328970498823684096.0000 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "1704/1704 [==============================] - 2s 1ms/step\n",
      "852/852 [==============================] - 7s 8ms/step - loss: 30656745472.0000 - val_loss: 110446744194843409677025280.0000 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "1704/1704 [==============================] - 2s 1ms/step\n",
      "852/852 [==============================] - 7s 8ms/step - loss: 23999105024.0000 - val_loss: 19531023964595831177216.0000 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "1704/1704 [==============================] - 2s 1ms/step\n",
      "852/852 [==============================] - 7s 8ms/step - loss: 18953414656.0000 - val_loss: 2016183875087398172884992.0000 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "1704/1704 [==============================] - 2s 1ms/step\n",
      "852/852 [==============================] - 7s 8ms/step - loss: 15224202240.0000 - val_loss: 236544430474002432.0000 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "1704/1704 [==============================] - 2s 1ms/step\n",
      "852/852 [==============================] - 7s 8ms/step - loss: 12268038144.0000 - val_loss: 146341773312.0000 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "1704/1704 [==============================] - 2s 1ms/step\n",
      "852/852 [==============================] - 7s 8ms/step - loss: 9946646528.0000 - val_loss: 12123541762811625472.0000 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "1704/1704 [==============================] - 2s 1ms/step\n",
      "852/852 [==============================] - 7s 8ms/step - loss: 8241866752.0000 - val_loss: 1082277953536.0000 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "1704/1704 [==============================] - 2s 1ms/step\n",
      "852/852 [==============================] - 7s 8ms/step - loss: 6211756032.0000 - val_loss: 163316498432.0000 - lr: 1.0000e-04\n",
      "Epoch 12/100\n",
      "1704/1704 [==============================] - 2s 1ms/step\n",
      "852/852 [==============================] - 6s 8ms/step - loss: 4714739712.0000 - val_loss: 4405276283240448.0000 - lr: 1.0000e-04\n",
      "Epoch 13/100\n",
      "1704/1704 [==============================] - 2s 1ms/step\n",
      "852/852 [==============================] - 7s 8ms/step - loss: 3610052352.0000 - val_loss: 1164653980869984256.0000 - lr: 1.0000e-04\n",
      "Epoch 14/100\n",
      "1704/1704 [==============================] - 2s 1ms/step\n",
      "852/852 [==============================] - 7s 8ms/step - loss: 2602166784.0000 - val_loss: 45369647955968.0000 - lr: 1.0000e-04\n",
      "Epoch 15/100\n",
      "1704/1704 [==============================] - 2s 1ms/step\n",
      "852/852 [==============================] - 7s 8ms/step - loss: 1832428288.0000 - val_loss: 3343084421120.0000 - lr: 1.0000e-04\n",
      "Epoch 16/100\n",
      "1704/1704 [==============================] - 2s 1ms/step\n",
      "852/852 [==============================] - 7s 8ms/step - loss: 1281907328.0000 - val_loss: 52760797184.0000 - lr: 1.0000e-04\n",
      "Epoch 17/100\n",
      "1704/1704 [==============================] - 2s 1ms/step\n",
      "852/852 [==============================] - 7s 8ms/step - loss: 917150592.0000 - val_loss: 2653106944.0000 - lr: 1.0000e-04\n",
      "Epoch 18/100\n",
      "1704/1704 [==============================] - 2s 1ms/step\n",
      "852/852 [==============================] - 6s 8ms/step - loss: 590454400.0000 - val_loss: 71762657280.0000 - lr: 1.0000e-04\n",
      "Epoch 19/100\n",
      "1704/1704 [==============================] - 2s 1ms/step\n",
      "852/852 [==============================] - 7s 8ms/step - loss: 390776320.0000 - val_loss: 14444774400.0000 - lr: 1.0000e-04\n",
      "Epoch 20/100\n",
      "1704/1704 [==============================] - 2s 1ms/step\n",
      "852/852 [==============================] - 7s 8ms/step - loss: 254800912.0000 - val_loss: 4239628032.0000 - lr: 1.0000e-04\n",
      "Epoch 21/100\n",
      "1704/1704 [==============================] - 2s 1ms/step\n",
      "852/852 [==============================] - 7s 8ms/step - loss: 162845680.0000 - val_loss: 37828681728.0000 - lr: 1.0000e-04\n",
      "Epoch 22/100\n",
      "1704/1704 [==============================] - 2s 1ms/step\n",
      "852/852 [==============================] - 7s 8ms/step - loss: 103760832.0000 - val_loss: 1873261696.0000 - lr: 1.0000e-04\n",
      "Epoch 23/100\n",
      "1704/1704 [==============================] - 2s 1ms/step\n",
      "852/852 [==============================] - 7s 8ms/step - loss: 66984616.0000 - val_loss: 19960473600.0000 - lr: 1.0000e-04\n",
      "Epoch 24/100\n",
      "1704/1704 [==============================] - 2s 1ms/step\n",
      "852/852 [==============================] - 7s 8ms/step - loss: 41615172.0000 - val_loss: 110050770944.0000 - lr: 1.0000e-04\n",
      "Epoch 25/100\n",
      "1704/1704 [==============================] - 2s 1ms/step\n",
      "852/852 [==============================] - 7s 8ms/step - loss: 26146838.0000 - val_loss: 9778891776.0000 - lr: 1.0000e-04\n",
      "Epoch 26/100\n",
      "1704/1704 [==============================] - 2s 1ms/step\n",
      "852/852 [==============================] - 7s 8ms/step - loss: 16303497.0000 - val_loss: 1106726656.0000 - lr: 1.0000e-04\n",
      "Epoch 27/100\n",
      "1704/1704 [==============================] - 2s 1ms/step\n",
      "852/852 [==============================] - 6s 8ms/step - loss: 10388605.0000 - val_loss: 10596281344.0000 - lr: 1.0000e-04\n",
      "Epoch 28/100\n",
      "1704/1704 [==============================] - 2s 1ms/step\n",
      "852/852 [==============================] - 7s 8ms/step - loss: 6564105.5000 - val_loss: 2253117184.0000 - lr: 1.0000e-04\n",
      "Epoch 29/100\n",
      "1704/1704 [==============================] - 2s 1ms/step\n",
      "852/852 [==============================] - 7s 8ms/step - loss: 4014607.5000 - val_loss: 26292664.0000 - lr: 1.0000e-04\n",
      "Epoch 30/100\n",
      "1704/1704 [==============================] - 2s 1ms/step\n",
      "852/852 [==============================] - 7s 8ms/step - loss: 2532685.0000 - val_loss: 6364373504.0000 - lr: 1.0000e-04\n",
      "Epoch 31/100\n",
      "1704/1704 [==============================] - 2s 1ms/step\n",
      "852/852 [==============================] - 7s 8ms/step - loss: 1585571.0000 - val_loss: 78337776.0000 - lr: 1.0000e-04\n",
      "Epoch 32/100\n",
      "1704/1704 [==============================] - 2s 1ms/step\n",
      "852/852 [==============================] - 7s 8ms/step - loss: 991985.1250 - val_loss: 247751872.0000 - lr: 1.0000e-04\n",
      "Epoch 33/100\n",
      "1704/1704 [==============================] - 2s 1ms/step\n",
      "852/852 [==============================] - 6s 7ms/step - loss: 624930.9375 - val_loss: 56315504.0000 - lr: 1.0000e-04\n",
      "Epoch 34/100\n",
      "1704/1704 [==============================] - 2s 1ms/step\n",
      "852/852 [==============================] - 7s 8ms/step - loss: 392168.8125 - val_loss: 78227608.0000 - lr: 1.0000e-04\n",
      "Epoch 35/100\n",
      "1704/1704 [==============================] - 2s 1ms/step\n",
      "852/852 [==============================] - 7s 8ms/step - loss: 245189.2969 - val_loss: 3842852.2500 - lr: 1.0000e-04\n",
      "Epoch 36/100\n",
      "1704/1704 [==============================] - 2s 1ms/step\n",
      "852/852 [==============================] - 7s 8ms/step - loss: 154077.3281 - val_loss: 1602740.7500 - lr: 1.0000e-04\n",
      "Epoch 37/100\n",
      "1704/1704 [==============================] - 2s 1ms/step\n",
      "852/852 [==============================] - 7s 8ms/step - loss: 98058.7578 - val_loss: 8813657.0000 - lr: 1.0000e-04\n",
      "Epoch 38/100\n",
      "1704/1704 [==============================] - 2s 1ms/step\n",
      "852/852 [==============================] - 6s 8ms/step - loss: 62153.7227 - val_loss: 21254576.0000 - lr: 1.0000e-04\n",
      "Epoch 39/100\n",
      "1704/1704 [==============================] - 2s 1ms/step\n",
      "852/852 [==============================] - 6s 7ms/step - loss: 38645.1914 - val_loss: 4593148.5000 - lr: 1.0000e-04\n",
      "Epoch 40/100\n",
      "1704/1704 [==============================] - 2s 1ms/step\n",
      "852/852 [==============================] - 6s 8ms/step - loss: 24709.3086 - val_loss: 3611102.5000 - lr: 1.0000e-04\n",
      "Epoch 41/100\n",
      "1704/1704 [==============================] - 2s 1ms/step\n",
      "852/852 [==============================] - 7s 8ms/step - loss: 15637.5371 - val_loss: 74094.9766 - lr: 1.0000e-04\n",
      "Epoch 42/100\n",
      "1704/1704 [==============================] - 2s 1ms/step\n",
      "852/852 [==============================] - 7s 8ms/step - loss: 9721.4697 - val_loss: 223418.6719 - lr: 1.0000e-04\n",
      "Epoch 43/100\n",
      "1704/1704 [==============================] - 2s 1ms/step\n",
      "852/852 [==============================] - 7s 8ms/step - loss: 6210.0342 - val_loss: 201735.3281 - lr: 1.0000e-04\n",
      "Epoch 44/100\n",
      "1704/1704 [==============================] - 2s 1ms/step\n",
      "852/852 [==============================] - 7s 8ms/step - loss: 3999.1912 - val_loss: 2202206.7500 - lr: 1.0000e-04\n",
      "Epoch 45/100\n",
      "1704/1704 [==============================] - 2s 1ms/step\n",
      "852/852 [==============================] - 7s 8ms/step - loss: 2513.9563 - val_loss: 20639388.0000 - lr: 1.0000e-04\n",
      "Epoch 46/100\n",
      "1704/1704 [==============================] - 2s 1ms/step\n",
      "852/852 [==============================] - 7s 8ms/step - loss: 1610.5187 - val_loss: 7852.7456 - lr: 1.0000e-04\n",
      "Epoch 47/100\n",
      "1704/1704 [==============================] - 2s 1ms/step\n",
      "852/852 [==============================] - 6s 8ms/step - loss: 1068.3710 - val_loss: 237722.4219 - lr: 1.0000e-04\n",
      "Epoch 48/100\n",
      "1704/1704 [==============================] - 2s 1ms/step\n",
      "852/852 [==============================] - 7s 8ms/step - loss: 673.4807 - val_loss: 22829.7734 - lr: 1.0000e-04\n",
      "Epoch 49/100\n",
      "1704/1704 [==============================] - 2s 1ms/step\n",
      "852/852 [==============================] - 7s 8ms/step - loss: 431.6059 - val_loss: 1010765.5625 - lr: 1.0000e-04\n",
      "Epoch 50/100\n",
      "1704/1704 [==============================] - 2s 1ms/step\n",
      "852/852 [==============================] - 7s 8ms/step - loss: 289.6377 - val_loss: 15002.9922 - lr: 1.0000e-04\n",
      "Epoch 51/100\n",
      "1704/1704 [==============================] - 2s 1ms/step\n",
      "852/852 [==============================] - 7s 8ms/step - loss: 195.2928 - val_loss: 29750.3281 - lr: 1.0000e-04\n",
      "Epoch 52/100\n",
      "1704/1704 [==============================] - 2s 1ms/step\n",
      "852/852 [==============================] - 7s 8ms/step - loss: 137.1259 - val_loss: 693.8217 - lr: 1.0000e-04\n",
      "Epoch 53/100\n",
      "1704/1704 [==============================] - 2s 1ms/step\n",
      "852/852 [==============================] - 7s 8ms/step - loss: 99.4793 - val_loss: 14644.7393 - lr: 1.0000e-04\n",
      "Epoch 54/100\n",
      "1704/1704 [==============================] - 2s 1ms/step\n",
      "852/852 [==============================] - 6s 8ms/step - loss: 75.6322 - val_loss: 759.9718 - lr: 1.0000e-04\n",
      "Epoch 55/100\n",
      "1704/1704 [==============================] - 2s 1ms/step\n",
      "852/852 [==============================] - 6s 8ms/step - loss: 60.7133 - val_loss: 436.3485 - lr: 1.0000e-04\n",
      "Epoch 56/100\n",
      "1704/1704 [==============================] - 2s 1ms/step\n",
      "852/852 [==============================] - 7s 8ms/step - loss: 51.3978 - val_loss: 985.3936 - lr: 1.0000e-04\n",
      "Epoch 57/100\n",
      "1704/1704 [==============================] - 2s 1ms/step\n",
      "852/852 [==============================] - 6s 8ms/step - loss: 45.7205 - val_loss: 15541.4570 - lr: 1.0000e-04\n",
      "Epoch 58/100\n",
      "1704/1704 [==============================] - 2s 1ms/step\n",
      "852/852 [==============================] - 7s 8ms/step - loss: 42.1627 - val_loss: 106.8511 - lr: 1.0000e-04\n",
      "Epoch 59/100\n",
      "1704/1704 [==============================] - 2s 1ms/step\n",
      "852/852 [==============================] - 6s 8ms/step - loss: 40.2413 - val_loss: 935.9329 - lr: 1.0000e-04\n",
      "Epoch 60/100\n",
      "1704/1704 [==============================] - 2s 1ms/step\n",
      "852/852 [==============================] - 6s 7ms/step - loss: 39.0751 - val_loss: 55.1365 - lr: 1.0000e-04\n",
      "Epoch 61/100\n",
      "1704/1704 [==============================] - 2s 1ms/step\n",
      "852/852 [==============================] - 6s 8ms/step - loss: 38.4518 - val_loss: 70.6668 - lr: 1.0000e-04\n",
      "Epoch 62/100\n",
      "1704/1704 [==============================] - 2s 1ms/step\n",
      "852/852 [==============================] - 6s 8ms/step - loss: 38.1439 - val_loss: 14055.2373 - lr: 1.0000e-04\n",
      "Epoch 63/100\n",
      "1704/1704 [==============================] - 2s 1ms/step\n",
      "852/852 [==============================] - 7s 8ms/step - loss: 38.0263 - val_loss: 364.2190 - lr: 1.0000e-04\n",
      "Epoch 64/100\n",
      "1704/1704 [==============================] - 2s 1ms/step\n",
      "852/852 [==============================] - 6s 8ms/step - loss: 37.9585 - val_loss: 320.4366 - lr: 1.0000e-04\n",
      "Epoch 65/100\n",
      "1704/1704 [==============================] - 2s 1ms/step\n",
      "852/852 [==============================] - 7s 8ms/step - loss: 37.9389 - val_loss: 45.3303 - lr: 1.0000e-04\n",
      "Epoch 66/100\n",
      "1704/1704 [==============================] - 2s 1ms/step\n",
      "852/852 [==============================] - 6s 8ms/step - loss: 37.9167 - val_loss: 48.3656 - lr: 1.0000e-04\n",
      "Epoch 67/100\n",
      "1704/1704 [==============================] - 2s 1ms/step\n",
      "852/852 [==============================] - 7s 8ms/step - loss: 37.9259 - val_loss: 44.9368 - lr: 1.0000e-04\n",
      "Epoch 68/100\n",
      "1704/1704 [==============================] - 2s 1ms/step\n",
      "852/852 [==============================] - 7s 8ms/step - loss: 37.8932 - val_loss: 141.0496 - lr: 1.0000e-04\n",
      "Epoch 69/100\n",
      "1704/1704 [==============================] - 2s 1ms/step\n",
      "852/852 [==============================] - 7s 8ms/step - loss: 37.8419 - val_loss: 40.0186 - lr: 1.0000e-04\n",
      "Epoch 70/100\n",
      "1704/1704 [==============================] - 2s 1ms/step\n",
      "852/852 [==============================] - 6s 8ms/step - loss: 37.8308 - val_loss: 42.7764 - lr: 1.0000e-04\n",
      "Epoch 71/100\n",
      "1704/1704 [==============================] - 2s 1ms/step\n",
      "852/852 [==============================] - 7s 8ms/step - loss: 37.7883 - val_loss: 40.8556 - lr: 1.0000e-04\n",
      "Epoch 72/100\n",
      "1704/1704 [==============================] - 2s 1ms/step\n",
      "852/852 [==============================] - 6s 8ms/step - loss: 37.7427 - val_loss: 213.0987 - lr: 1.0000e-04\n",
      "Epoch 73/100\n",
      "1704/1704 [==============================] - 2s 1ms/step\n",
      "852/852 [==============================] - 6s 8ms/step - loss: 37.7046 - val_loss: 39.3040 - lr: 1.0000e-04\n",
      "Epoch 74/100\n",
      "1704/1704 [==============================] - 2s 1ms/step\n",
      "852/852 [==============================] - 6s 8ms/step - loss: 37.6640 - val_loss: 39.3998 - lr: 1.0000e-04\n",
      "Epoch 75/100\n",
      "1704/1704 [==============================] - 2s 1ms/step\n",
      "852/852 [==============================] - 7s 8ms/step - loss: 37.6286 - val_loss: 67.8787 - lr: 1.0000e-04\n",
      "Epoch 76/100\n",
      "1704/1704 [==============================] - 2s 1ms/step\n",
      "852/852 [==============================] - 6s 8ms/step - loss: 37.5818 - val_loss: 40.3467 - lr: 1.0000e-04\n",
      "Epoch 77/100\n",
      "1704/1704 [==============================] - 2s 1ms/step\n",
      "852/852 [==============================] - 6s 8ms/step - loss: 37.5802 - val_loss: 39.7070 - lr: 1.0000e-04\n",
      "Epoch 78/100\n",
      "1704/1704 [==============================] - 2s 1ms/step\n",
      "852/852 [==============================] - 7s 8ms/step - loss: 37.5313 - val_loss: 37.5797 - lr: 1.0000e-04\n",
      "Epoch 79/100\n",
      "1704/1704 [==============================] - 2s 1ms/step\n",
      "852/852 [==============================] - 6s 8ms/step - loss: 37.5096 - val_loss: 46.0664 - lr: 1.0000e-04\n",
      "Epoch 80/100\n",
      "1704/1704 [==============================] - 2s 1ms/step\n",
      "852/852 [==============================] - 6s 8ms/step - loss: 37.4825 - val_loss: 40.2439 - lr: 1.0000e-04\n",
      "Epoch 81/100\n",
      "1704/1704 [==============================] - 2s 1ms/step\n",
      "852/852 [==============================] - 7s 8ms/step - loss: 37.4656 - val_loss: 39.4734 - lr: 1.0000e-04\n",
      "Epoch 82/100\n",
      "1704/1704 [==============================] - 2s 1ms/step\n",
      "852/852 [==============================] - 6s 8ms/step - loss: 37.5479 - val_loss: 39.0308 - lr: 1.0000e-04\n",
      "Epoch 83/100\n",
      "1704/1704 [==============================] - 2s 1ms/step\n",
      "852/852 [==============================] - 6s 8ms/step - loss: 37.4409 - val_loss: 44.4702 - lr: 1.0000e-04\n",
      "Epoch 84/100\n",
      "1704/1704 [==============================] - 2s 1ms/step\n",
      "852/852 [==============================] - 7s 8ms/step - loss: 37.4405 - val_loss: 42.1305 - lr: 1.0000e-04\n",
      "Epoch 85/100\n",
      "1704/1704 [==============================] - 2s 1ms/step\n",
      "852/852 [==============================] - 7s 8ms/step - loss: 37.4198 - val_loss: 49.0125 - lr: 1.0000e-04\n",
      "Epoch 86/100\n",
      "1704/1704 [==============================] - 2s 1ms/step\n",
      "852/852 [==============================] - 7s 8ms/step - loss: 37.4130 - val_loss: 38.6521 - lr: 1.0000e-04\n",
      "Epoch 87/100\n",
      "1704/1704 [==============================] - 2s 1ms/step\n",
      "852/852 [==============================] - 7s 8ms/step - loss: 37.4129 - val_loss: 39.8997 - lr: 1.0000e-04\n",
      "Epoch 88/100\n",
      "1704/1704 [==============================] - 2s 1ms/step\n",
      "852/852 [==============================] - 7s 8ms/step - loss: 37.3964 - val_loss: 40.9495 - lr: 1.0000e-04\n",
      "Epoch 89/100\n",
      "1704/1704 [==============================] - 2s 1ms/step\n",
      "852/852 [==============================] - 7s 8ms/step - loss: 37.3842 - val_loss: 37.7177 - lr: 1.0000e-04\n",
      "Epoch 90/100\n",
      "1704/1704 [==============================] - 2s 1ms/step\n",
      "852/852 [==============================] - 7s 8ms/step - loss: 37.3741 - val_loss: 43.1464 - lr: 1.0000e-04\n",
      "Epoch 91/100\n",
      "1704/1704 [==============================] - 2s 1ms/step\n",
      "852/852 [==============================] - 7s 8ms/step - loss: 37.3609 - val_loss: 39.7248 - lr: 1.0000e-04\n",
      "Epoch 92/100\n",
      "1704/1704 [==============================] - 2s 1ms/step\n",
      "852/852 [==============================] - 6s 8ms/step - loss: 37.3549 - val_loss: 38.7052 - lr: 1.0000e-04\n",
      "Epoch 93/100\n",
      "1704/1704 [==============================] - 2s 1ms/step\n",
      "852/852 [==============================] - 7s 8ms/step - loss: 37.3425 - val_loss: 43.7828 - lr: 1.0000e-04\n",
      "Epoch 94/100\n",
      "1704/1704 [==============================] - 2s 1ms/step\n",
      "852/852 [==============================] - 7s 8ms/step - loss: 37.3295 - val_loss: 51.2191 - lr: 1.0000e-04\n",
      "Epoch 95/100\n",
      "1704/1704 [==============================] - 2s 1ms/step\n",
      "852/852 [==============================] - 7s 8ms/step - loss: 37.3166 - val_loss: 42.9528 - lr: 1.0000e-04\n",
      "Epoch 96/100\n",
      "1704/1704 [==============================] - 2s 1ms/step\n",
      "852/852 [==============================] - 7s 8ms/step - loss: 37.3090 - val_loss: 40.6568 - lr: 1.0000e-04\n",
      "Epoch 97/100\n",
      "1704/1704 [==============================] - 2s 1ms/step\n",
      "852/852 [==============================] - 7s 8ms/step - loss: 37.3025 - val_loss: 42.5153 - lr: 1.0000e-04\n",
      "Epoch 98/100\n",
      "1704/1704 [==============================] - 2s 1ms/step\n",
      "852/852 [==============================] - 7s 8ms/step - loss: 37.3036 - val_loss: 37.9384 - lr: 1.0000e-04\n",
      "Epoch 99/100\n",
      "1704/1704 [==============================] - 2s 1ms/step\n",
      "852/852 [==============================] - 6s 8ms/step - loss: 37.2931 - val_loss: 38.0996 - lr: 1.0000e-04\n",
      "Epoch 100/100\n",
      "1704/1704 [==============================] - 2s 1ms/step\n",
      "852/852 [==============================] - 7s 8ms/step - loss: 37.2809 - val_loss: 40.8101 - lr: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "# Train the neural network\n",
    "history = DeepNet.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_valid,y_valid),\n",
    "    batch_size=BATCHSIZE,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks = [early_stopping,reduce_learn_on_plateau,PredictOnEpoch(DeepNet,X_train,y_train),cb,cp_callback],\n",
    "    use_multiprocessing=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss and validation curves vs epoch\n",
    "history_df = pd.DataFrame(history.history)\n",
    "np.log(history_df.loc[:, [\"loss\",\"val_loss\"]]).plot()\n",
    "history_df.to_csv('/home/physics/phujdj/DeepLearningParticlePhysics/history.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "673.0330443649727\n"
     ]
    }
   ],
   "source": [
    "print(sum(cb.logs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum validation loss: 37.28086471557617\n"
     ]
    }
   ],
   "source": [
    "# Output to the console the minimum epoch\n",
    "print(\"Minimum validation loss: {}\".format(history_df[\"loss\"].min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2130/2130 - 3s - loss: 40.8428 - 3s/epoch - 2ms/step\n",
      "The Loaded DeepNet has loss:  40.84280776977539\n"
     ]
    }
   ],
   "source": [
    "#Evaluate the entire performance of the model\n",
    "loss = DeepNet.evaluate(tracks,bhads,verbose = 2)\n",
    "print(\"The Loaded DeepNet has loss: \", loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('SpocFit')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a05ddcd8ffea9a6a7d2e914b733df5445b717626b5b8c92c04bfc4eb6e7f5cba"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
