{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "cf52dc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant modules\n",
    "import awkward as ak\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras.layers as layers\n",
    "import keras\n",
    "from Sum import Sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "f85a8243",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial parameters\n",
    "MASKVAL = -999 # This value is introduced to ensure arrays are regular (Of the same size). They will be masked later by the network\n",
    "MAXTRACKS = 32 # This value is the maximum number of tracks allowed per event\n",
    "BATCHSIZE = 64 # This is the batch size of the mini batches used during training\n",
    "EPOCHS = 1000 # This is the default number of epochs for which the neural network will train providing that early stopping does not occur\n",
    "MAXEVENTS = 1e20 #This is the maximum number of events that will the program will accept\n",
    "LR = 1e-4 #This is the default learning rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "10435331",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the associated tracks for each jet\n",
    "def Match_Tracks(jets, tracks):\n",
    "    \"\"\"Used to determine if a set of tracks belong to a particular set of jets\"\"\"\n",
    "\n",
    "    jet_eta = jets[\"AnalysisAntiKt4TruthJets_eta\"]\n",
    "    jet_phi = jets[\"AnalysisAntiKt4TruthJets_phi\"] \n",
    "\n",
    "    tracks_eta = tracks[\"AnalysisTracks_eta\"]\n",
    "    tracks_phi = tracks[\"AnalysisTracks_phi\"]\n",
    "\n",
    "    delta_etas = jet_eta - tracks_eta\n",
    "    delta_phis = np.abs(jet_phi - tracks_phi)\n",
    "\n",
    "    # Map the phis from a cyclical period onto a linear relation\n",
    "    ak.where(delta_phis > np.pi, delta_phis - np.pi, delta_phis)\n",
    "\n",
    "    # Returns a list of true and false, determining which tracks belong to those jets.\n",
    "    return np.sqrt(delta_phis**2 + delta_etas**2) < 0.4 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "c5f5e74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert from cylindrical to cartesian coordinates\n",
    "def pt_eta_phi_2_px_py_pz_jets(pt_eta_phi):\n",
    "    \"\"\"Converts the cylindrical polar coordinates to cartesian coordinates for jets\"\"\"\n",
    "\n",
    "    # Seperate the pts, etas and phis\n",
    "    pts = pt_eta_phi[:, 0:1]\n",
    "    etas = pt_eta_phi[:, 1:2]\n",
    "    phis = pt_eta_phi[:, 2:3]\n",
    "\n",
    "    # Convert from polar to cartesian\n",
    "    pxs = pts * np.cos(phis)\n",
    "    pys = pts * np.sin(phis)\n",
    "    pzs = pts * np.sinh(etas)\n",
    "\n",
    "    # Check to see if there are any infinities\n",
    "    isinf = np.isinf(pzs)\n",
    "\n",
    "    if np.any(isinf):\n",
    "        print(\"Infinities in eta detected!\")\n",
    "        print(etas[isinf])\n",
    "        raise ValueError(\"Infinity from sinh(eta) has been detected\")\n",
    "\n",
    "    # Returns the momentum vector\n",
    "    return np.concatenate([pxs, pys, pzs], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e31bd425",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pt_eta_phi_2_px_py_pz_tracks(pt_eta_phi, MASKVAL=-999):\n",
    "    \"\"\"Converts the cylindrical polar coordinates to cartesian coordinates for jets\"\"\"\n",
    "\n",
    "    # Seperate the pts, etas and phis\n",
    "    pts = pt_eta_phi[:, :, 0:1]\n",
    "    etas = pt_eta_phi[:, :, 1:2]\n",
    "    phis = pt_eta_phi[:, :, 2:3]\n",
    "\n",
    "    # Convert from polar to cartesian\n",
    "    # Transforms only the non masked values from cylindrical to cartesian coordinates. Mask values are left unchanged.\n",
    "    mask1 = pts == MASKVAL \n",
    "    mask2 = phis == MASKVAL\n",
    "    mask3 = etas == MASKVAL\n",
    "    pxs = np.where(mask1 | mask2, pts, pts * np.cos(phis)) \n",
    "    pys = np.where(mask1 | mask2, pts, pts * np.sin(phis))\n",
    "    pzs = np.where(mask1 | mask3, pts, pts * np.sinh(etas))\n",
    "\n",
    "    # Check to see if there are any infinities\n",
    "    isinf = np.isinf(pzs)\n",
    "\n",
    "    if np.any(isinf):\n",
    "        print(\"Infinities in eta detected!\")\n",
    "        print(etas[isinf])\n",
    "        raise ValueError(\"Infinity from sinh(eta) has been detected\")\n",
    "\n",
    "    # Returns the momentum vector in cartesian coordinates\n",
    "    return np.concatenate([pxs, pys, pzs], axis=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "a032c4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pt_eta_phi2_px_py_pz_predicted_tracks(predictions):\n",
    "    #Obtain the pts,etas and phis\n",
    "    pts = predictions[:,0:1]\n",
    "    etas = predictions[:,1:2]\n",
    "    phis = predictions[:,2:3]\n",
    "\n",
    "    # Convert from polar to cartesian\n",
    "    # Transforms only the non masked values from cylindrical to cartesian coordinates. Mask values are left unchanged.\n",
    "    pxs =  pts * np.cos(phis)\n",
    "    pys =  pts * np.sin(phis)\n",
    "    pzs =  pts * np.sinh(etas)\n",
    "\n",
    "    # Check to see if there are any infinities\n",
    "    isinf = np.isinf(pzs)\n",
    "\n",
    "    if np.any(isinf):\n",
    "        print(\"Infinities in eta detected!\")\n",
    "        print(etas[isinf])\n",
    "        raise ValueError(\"Infinity from sinh(eta) has been detected\")\n",
    "\n",
    "    # Returns the momentum vector in cartesian coordinates\n",
    "    return np.concatenate([pxs, pys, pzs], axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "dd743c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad(x_values, maxsize, MASKVAL=-999):\n",
    "    \"\"\"\n",
    "    Pads the inputs with nans to get to the maxsize\n",
    "    \"\"\"\n",
    "    #Pad the non-regular arrays with null values until they are all of the same size. Then replace the nulls with MASVAL\n",
    "    y_values = ak.fill_none(ak.pad_none(x_values, maxsize, axis=1, clip=True), MASKVAL)[:, :maxsize]\n",
    "    return ak.to_regular(y_values, axis=1) #Return the regular arrays\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "849df671",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(x_values, maxsize=-1, MASKVAL=-999):\n",
    "    \"\"\"\"Pads the input to ensure they are all of regular size and then zips together result\"\"\"\n",
    "    y_values = {} \n",
    "    for field in x_values.fields:\n",
    "        z_values = x_values[field]\n",
    "        if maxsize > 0:\n",
    "            z_values = pad(z_values, maxsize, MASKVAL)\n",
    "        y_values[field] = z_values\n",
    "\n",
    "    return ak.zip(y_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "c0f51140",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LogNormal_Loss_Function(true, meanscovs_matrix):\n",
    "    \"\"\"\n",
    "    This is a loss function hand crafted for the task of ensuring the neural network \n",
    "    learns to predict the true value of the transverse momentum and it's uncertainty\n",
    "    The logNormal constrains the neural network, by forcing upon it what it's output layers should be\n",
    "    and what the weights and biases of the neural network will be in order to predict the means, variances and covariances\n",
    "    \"\"\"\n",
    "    n_targets = np.shape(true)[1]\n",
    "    # The first n_target of the features are the means\n",
    "    means = meanscovs_matrix[:, :n_targets]\n",
    "    # The second n_target of the feautres are the standard deviations\n",
    "    logsigma = meanscovs_matrix[:, n_targets:2*n_targets]\n",
    "    # The rest of the targets are the covariances\n",
    "    logcosigma = meanscovs_matrix[:,2*n_targets:]\n",
    "\n",
    "    loss = 0\n",
    "    for n_target in range(n_targets): #Sum the individual losses and use that as the loss for the neural network\n",
    "        loss += ((means[:, n_target] - true[:, n_target])**2) / (2 * keras.backend.exp(logsigma[:, n_target])**2) + logsigma[:, n_target]\n",
    "\n",
    "    # Build loss function\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "abab3efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Normal_Accuracy_Metric(true,meanscovs_matrix):\n",
    "    \"\"\"\n",
    "    The primary function of the LogNormal loss function is to determine\n",
    "    best normal distribution to fit to the bhadron data. By including the \n",
    "    uncertainity however, the metric is not so usefull for error checking. \n",
    "    I have added accuracy metric to better measure the ability of the neural \n",
    "    network to predict the correct values\n",
    "    \"\"\"\n",
    "    # Determine the number of features we are predicting\n",
    "    n_targets = np.shape(true)[1]\n",
    "    \n",
    "    # Extract the means of the features\n",
    "    means = meanscovs_matrix[:,:n_targets]\n",
    "\n",
    "    Accuracy = []\n",
    "    for n_target in range(n_targets):\n",
    "        Accuracy.append(abs((means[:,n_target]-true[:,n_target])/true[:,n_target])*100)\n",
    "    Accuracy = tf.convert_to_tensor(Accuracy)\n",
    "    return keras.backend.mean(Accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "51140913",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LogNormal_Loss_Function_Check(true,meanscovs_matrix):\n",
    "    \"\"\"The role of this function is to calculate the loss for each individual b jet. This is used for the purpose of error checking\"\"\"\n",
    "    n_targets = np.shape(true)[0]\n",
    "    # Obtain data from convarience matrix\n",
    "    means = meanscovs_matrix[0, :n_targets]\n",
    "    # ensure diagonal is postive:\n",
    "    logsigma = meanscovs_matrix[0, n_targets:2*n_targets]\n",
    "\n",
    "    loss = []\n",
    "    for n_target in range(n_targets):\n",
    "        loss.append(((means[n_target] - true[n_target])**2) / (2 * keras.backend.exp(logsigma[n_target])**2) + logsigma[n_target])\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "fb387c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expontial_decay(lr0,s):\n",
    "    def exponential_decay_fn(epoch):\n",
    "        return lr0 * 0.95**(epoch/s)\n",
    "    return exponential_decay_fn\n",
    "exponential_decay_fn = expontial_decay(lr0 = LR,s = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "1b6ecfc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DeepSetNeuralNetwork(track_layers, jet_layers, n_targets,Learning_rate, MASKVAL=-999):\n",
    "    \"\"\"\n",
    "    This function lays out the Deep Set Neural Architecture\n",
    "    - A neural network is applied first to the tracks to extract information from the tracks.\n",
    "    - This information produces an ensemble space which, the outputs of which are then summed to produce\n",
    "        the inputs for the next layer\n",
    "    - A neural network is then applied to the jet data obtained from the tracks. \n",
    "        To perform current univariate regression.\n",
    "    \"\"\"\n",
    "    inputs = layers.Input(shape=(None, track_layers[0])) # Creates a layer for each input\n",
    "    outputs = inputs  # Creates another layer to pass the inputs onto the ouputs\n",
    "    outputs = layers.Masking(mask_value=MASKVAL)(outputs) # Masks the MASKVAl values\n",
    "\n",
    "    counter = 0\n",
    "    for nodes in track_layers[:-1]:\n",
    "        #The first neural network is a series of dense layers and is applied to each track using the time distributed layer\n",
    "        outputs = layers.TimeDistributed( \n",
    "            layers.Dense(nodes, activation=\"elu\", kernel_initializer= \"he_normal\"))(outputs) # We use relu and the corresponding he_normal for the activation function and bias initializer\n",
    "        if counter % 2 == 0: # Every two layers apply a dropout\n",
    "            outputs = layers.Dropout(0.2)(outputs)\n",
    "        else:\n",
    "            counter += 1\n",
    "        outputs = layers.BatchNormalization()(outputs) #Apply a batch norm to improve performance by preventing feature bias and overfitting\n",
    "\n",
    "    outputs = layers.TimeDistributed(layers.Dense( \n",
    "        track_layers[-1], activation='softmax'))(outputs) # Apply softmax to ouput the results of the track neural network as probabilities\n",
    "    outputs = Sum()(outputs) # Sum the outputs to make use of permutation invariance\n",
    "\n",
    "    counter = 0\n",
    "    for nodes in jet_layers: #Repeat of the track neural network without the need for the timedistributed layers\n",
    "        outputs = layers.Dense(nodes, activation='elu', kernel_initializer= \"he_normal\")(outputs)\n",
    "        if counter % 2 == 0:\n",
    "            outputs = layers.Dropout(0.2)(outputs)\n",
    "        else:\n",
    "            counter += 1\n",
    "        outputs = layers.BatchNormalization()(outputs)\n",
    "\n",
    "    outputs = layers.Dense(n_targets+n_targets*(n_targets+1)//2)(outputs) # The output will have a number of neurons needed to form the mean covariance function of the loss func\n",
    "\n",
    "    Model = keras.Model(inputs=inputs, outputs=outputs) #Create a keras model\n",
    "\n",
    "    # Specify the neural network's optimizer and loss function\n",
    "    Model.compile(\n",
    "    optimizer=keras.optimizers.Nadam(learning_rate=Learning_rate), # Optimizer used to train model\n",
    "    metrics = [Normal_Accuracy_Metric], # Metric used to assess true performance of model\n",
    "    loss=LogNormal_Loss_Function, #Loss function\n",
    "    )\n",
    "\n",
    "    return Model\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 (main, Apr  5 2022, 06:56:58) \n[GCC 7.5.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "a05ddcd8ffea9a6a7d2e914b733df5445b717626b5b8c92c04bfc4eb6e7f5cba"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
