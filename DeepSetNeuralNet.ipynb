{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf52dc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant modules\n",
    "import os\n",
    "import awkward as ak\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras.layers as layers\n",
    "from keras import callbacks\n",
    "import keras\n",
    "import uproot\n",
    "from Sum import Sum\n",
    "import sklearn as sk\n",
    "from numpy.lib.recfunctions import structured_to_unstructured\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import hffrag\n",
    "import keras_tuner as kt\n",
    "from hffrag import fixedbinning\n",
    "from hffrag import binneddensity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03fbe6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A magic operator to allow Jupyter Notebooks to display matplotlib plots as outputs of cells\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "646b0267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data is being stored in a tree datastructure.\n",
    "# We access the charm root using this command\n",
    "tree = uproot.open(\"hffrag.root:CharmAnalysis\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f85a8243",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial parameters\n",
    "MASKVAL = -999 # This value is introduced to ensure arrays are regular (Of the same size). They will be masked later by the network\n",
    "MAXTRACKS = 8 # This value is the maximum number of tracks allowed per event\n",
    "BATCHSIZE = 32 # This is the batch size of the mini batches used during training\n",
    "EPOCHS = 1000 # This is the default number of epochs for which the neural network will train providing that early stopping does not occur\n",
    "MAXEVENTS = 1e20 #This is the maximum number of events that will the program will accept\n",
    "LR = 1e-4 #This is the default learning rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10435331",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the associated tracks for each jet\n",
    "def Match_Tracks(jets, tracks):\n",
    "    \"\"\"Used to determine if a set of tracks belong to a particular set of jets\"\"\"\n",
    "\n",
    "    jet_eta = jets[\"AnalysisAntiKt4TruthJets_eta\"]\n",
    "    jet_phi = jets[\"AnalysisAntiKt4TruthJets_phi\"] \n",
    "\n",
    "    tracks_eta = tracks[\"AnalysisTracks_eta\"]\n",
    "    tracks_phi = tracks[\"AnalysisTracks_phi\"]\n",
    "\n",
    "    delta_etas = jet_eta - tracks_eta\n",
    "    delta_phis = np.abs(jet_phi - tracks_phi)\n",
    "\n",
    "    # Map the phis from a cyclical period onto a linear relation\n",
    "    ak.where(delta_phis > np.pi, delta_phis - np.pi, delta_phis)\n",
    "\n",
    "    # Returns a list of true and false, determining which tracks belong to those jets.\n",
    "    return np.sqrt(delta_phis**2 + delta_etas**2) < 0.4 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c5f5e74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert from cylindrical to cartesian coordinates\n",
    "def pt_eta_phi_2_px_py_pz_jets(pt_eta_phi):\n",
    "    \"\"\"Converts the cylindrical polar coordinates to cartesian coordinates for jets\"\"\"\n",
    "\n",
    "    # Seperate the pts, etas and phis\n",
    "    pts = pt_eta_phi[:, 0:1]\n",
    "    etas = pt_eta_phi[:, 1:2]\n",
    "    phis = pt_eta_phi[:, 2:3]\n",
    "\n",
    "    # Convert from polar to cartesian\n",
    "    pxs = pts * np.cos(phis)\n",
    "    pys = pts * np.sin(phis)\n",
    "    pzs = pts * np.sinh(etas)\n",
    "\n",
    "    # Check to see if there are any infinities\n",
    "    isinf = np.isinf(pzs)\n",
    "\n",
    "    if np.any(isinf):\n",
    "        print(\"Infinities in eta detected!\")\n",
    "        print(etas[isinf])\n",
    "        raise ValueError(\"Infinity from sinh(eta) has been detected\")\n",
    "\n",
    "    # Returns the momentum vector\n",
    "    return np.concatenate([pxs, pys, pzs], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e31bd425",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pt_eta_phi_2_px_py_pz_tracks(pt_eta_phi, MASKVAL=-999):\n",
    "    \"\"\"Converts the cylindrical polar coordinates to cartesian coordinates for jets\"\"\"\n",
    "\n",
    "    # Seperate the pts, etas and phis\n",
    "    pts = pt_eta_phi[:, :, 0:1]\n",
    "    etas = pt_eta_phi[:, :, 1:2]\n",
    "    phis = pt_eta_phi[:, :, 2:3]\n",
    "\n",
    "    # Convert from polar to cartesian\n",
    "    # Transforms only the non masked values from cylindrical to cartesian coordinates. Mask values are left unchanged.\n",
    "    mask1 = pts == MASKVAL \n",
    "    mask2 = phis == MASKVAL\n",
    "    mask3 = etas == MASKVAL\n",
    "    pxs = np.where(mask1 | mask2, pts, pts * np.cos(phis)) \n",
    "    pys = np.where(mask1 | mask2, pts, pts * np.sin(phis))\n",
    "    pzs = np.where(mask1 | mask3, pts, pts * np.sinh(etas))\n",
    "\n",
    "    # Check to see if there are any infinities\n",
    "    isinf = np.isinf(pzs)\n",
    "\n",
    "    if np.any(isinf):\n",
    "        print(\"Infinities in eta detected!\")\n",
    "        print(etas[isinf])\n",
    "        raise ValueError(\"Infinity from sinh(eta) has been detected\")\n",
    "\n",
    "    # Returns the momentum vector in cartesian coordinates\n",
    "    return np.concatenate([pxs, pys, pzs], axis=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd743c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad(x_values, maxsize, MASKVAL=-999):\n",
    "    \"\"\"\n",
    "    Pads the inputs with nans to get to the maxsize\n",
    "    \"\"\"\n",
    "    #Pad the non-regular arrays with null values until they are all of the same size. Then replace the nulls with MASVAL\n",
    "    y_values = ak.fill_none(ak.pad_none(x_values, maxsize, axis=1, clip=True), MASKVAL)[:, :maxsize]\n",
    "    return ak.to_regular(y_values, axis=1) #Return the regular arrays\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "849df671",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(x_values, maxsize=-1, MASKVAL=-999):\n",
    "    \"\"\"\"Pads the input to ensure they are all of regular size and then zips together result\"\"\"\n",
    "    y_values = {} \n",
    "    for field in x_values.fields:\n",
    "        z_values = x_values[field]\n",
    "        if maxsize > 0:\n",
    "            z_values = pad(z_values, maxsize, MASKVAL)\n",
    "        y_values[field] = z_values\n",
    "\n",
    "    return ak.zip(y_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c0f51140",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LogNormal_Loss_Function(true, meanscovs_matrix):\n",
    "    \"\"\"\n",
    "    This is a loss function hand crafted for the task of ensuring the neural network \n",
    "    learns to predict the true value of the transverse momentum and it's uncertainty\n",
    "    The logNormal constrains the neural network, by forcing upon it what it's output layers should be\n",
    "    and what the weights and biases of the neural network will be in order to predict the means, variances and covariances\n",
    "    \"\"\"\n",
    "    n_targets = np.shape(true)[1]\n",
    "    # The first n_target of the features are the means\n",
    "    means = meanscovs_matrix[:, :n_targets]\n",
    "    # The second n_target of the feautres are the standard deviations\n",
    "    logsigma = meanscovs_matrix[:, n_targets:2*n_targets]\n",
    "    # The rest of the targets are the covariances\n",
    "    logcosigma = meanscovs_matrix[:,2*n_targets:]\n",
    "\n",
    "    loss = 0\n",
    "    for n_target in range(n_targets): #Sum the individual losses and use that as the loss for the neural network\n",
    "        loss += ((means[:, n_target] - true[:, n_target])**2) / (2 * keras.backend.exp(logsigma[:, n_target])**2) + logsigma[:, n_target]\n",
    "\n",
    "    # Build loss function\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "51140913",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LogNormal_Loss_Function_Check(true,meanscovs_matrix):\n",
    "    \"\"\"The role of this function is to calculate the loss for each individual b jet. This is used for the purpose of error checking\"\"\"\n",
    "    n_targets = np.shape(true)[0]\n",
    "    # Obtain data from convarience matrix\n",
    "    means = meanscovs_matrix[0, :n_targets]\n",
    "    # ensure diagonal is postive:\n",
    "    logsigma = meanscovs_matrix[0, n_targets:2*n_targets]\n",
    "\n",
    "    loss = 0\n",
    "    for n_target in range(n_targets):\n",
    "        loss += ((means[n_target] - true[n_target])**2) / (2 * keras.backend.exp(logsigma[n_target])**2) + logsigma[n_target]\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1b6ecfc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DeepSetNeuralNetwork(track_layers, jet_layers, n_targets,Learning_rate, MASKVAL=-999):\n",
    "    \"\"\"\n",
    "    This function lays out the Deep Set Neural Architecture\n",
    "    - A neural network is applied first to the tracks to extract information from the tracks.\n",
    "    - This information produces an ensemble space which, the outputs of which are then summed to produce\n",
    "        the inputs for the next layer\n",
    "    - A neural network is then applied to the jet data obtained from the tracks. \n",
    "        To perform current univariate regression.\n",
    "    \"\"\"\n",
    "    inputs = layers.Input(shape=(None, track_layers[0])) # Creates a layer for each input\n",
    "    outputs = inputs  # Creates another layer to pass the inputs onto the ouputs\n",
    "    outputs = layers.Masking(mask_value=MASKVAL)(outputs) # Masks the MASKVAl values\n",
    "\n",
    "    counter = 0\n",
    "    for nodes in track_layers[:-1]:\n",
    "        #The first neural network is a series of dense layers and is applied to each track using the time distributed layer\n",
    "        outputs = layers.TimeDistributed( \n",
    "            layers.Dense(nodes, activation=\"relu\", kernel_initializer= \"he_normal\"))(outputs) # We use relu and the corresponding he_normal for the activation function and bias initializer\n",
    "        if counter % 4 == 0: # Every four layers apply a dropout\n",
    "            outputs = layers.Dropout(0.01)(outputs)\n",
    "        else:\n",
    "            counter += 1\n",
    "        outputs = layers.BatchNormalization()(outputs) #Apply a batch norm to improve performance by preventing feature bias and overfitting\n",
    "\n",
    "    outputs = layers.TimeDistributed(layers.Dense( \n",
    "        track_layers[-1], activation='softmax'))(outputs) # Apply softmax to ouput the results of the track neural network as probabilities\n",
    "    outputs = Sum()(outputs) # Sum the outputs to make use of permutation invariance\n",
    "\n",
    "    counter = 0\n",
    "    for nodes in jet_layers: #Repeat of the track neural network without the need for the timedistributed layers\n",
    "        outputs = layers.Dense(nodes, activation='relu', kernel_initializer= \"he_normal\")(outputs)\n",
    "        if counter % 4 == 0:\n",
    "            outputs = layers.Dropout(0.01)(outputs)\n",
    "        else:\n",
    "            counter += 1\n",
    "        outputs = layers.BatchNormalization()(outputs)\n",
    "\n",
    "    outputs = layers.Dense(n_targets+n_targets*(n_targets+1)//2)(outputs) # The output will have a number of neurons needed to form the mean covariance function of the loss func\n",
    "\n",
    "    Model = keras.Model(inputs=inputs, outputs=outputs) #Create a keras model\n",
    "\n",
    "    # Specify the neural network's optimizer and loss function\n",
    "    Model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=Learning_rate,clipnorm = 1.0),\n",
    "    loss=LogNormal_Loss_Function\n",
    "    )\n",
    "\n",
    "    return Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "09cc7efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the features we wish to study\n",
    "track_features = [\"AnalysisTracks_pt\", \"AnalysisTracks_eta\", \"AnalysisTracks_phi\", \"AnalysisTracks_z0sinTheta\",\n",
    "                  \"AnalysisTracks_d0sig\", \"AnalysisTracks_d0\", \"AnalysisTracks_d0sigPV\", \"AnalysisTracks_d0PV\"]\n",
    "jet_features = [\"AnalysisAntiKt4TruthJets_pt\", \"AnalysisAntiKt4TruthJets_eta\", \"AnalysisAntiKt4TruthJets_phi\",\n",
    "                \"AnalysisAntiKt4TruthJets_ghostB_pt\", \"AnalysisAntiKt4TruthJets_ghostB_eta\",\"AnalysisAntiKt4TruthJets_ghostB_phi\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "94fb5db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data from the root file\n",
    "features = tree.arrays(jet_features+track_features, entry_stop=MAXEVENTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the events of interest\n",
    "events = features[ak.sum(\n",
    "    features[\"AnalysisAntiKt4TruthJets_pt\"] > 25000, axis=1) > 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of jets to train on is:  141329\n",
      "The number of track features is:  8\n"
     ]
    }
   ],
   "source": [
    "# Displays the number of jets being trained on\n",
    "jets = events[jet_features][:, 0]\n",
    "print(\"The number of jets to train on is: \", len(jets))\n",
    "print(\"The number of track features is: \",len(track_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select tracks from the events\n",
    "tracks = events[track_features]\n",
    "\n",
    "# Match the tracks to the jets\n",
    "matchedtracks = tracks[Match_Tracks(jets, tracks)]\n",
    "\n",
    "# Pad and Flatten the data\n",
    "matchedtracks = flatten(matchedtracks, MAXTRACKS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3 outputs\n",
      "There are 8 inputs\n"
     ]
    }
   ],
   "source": [
    "# Identify the the bottom jets and their associated tracks\n",
    "bjets = ak.sum(jets[\"AnalysisAntiKt4TruthJets_ghostB_pt\"] > 5000, axis=1) > 0\n",
    "jets = jets[bjets]\n",
    "\n",
    "# Obtain the pt, eta and phi of each b hadron jet\n",
    "bhads_pt = jets[\"AnalysisAntiKt4TruthJets_ghostB_pt\"][:, 0].to_numpy()\n",
    "bhads_eta = jets[\"AnalysisAntiKt4TruthJets_ghostB_eta\"][:,0].to_numpy()\n",
    "bhads_phi = jets[\"AnalysisAntiKt4TruthJets_ghostB_phi\"][:,0].to_numpy()\n",
    "\n",
    "bhads = np.stack([bhads_pt,bhads_eta,bhads_phi],axis = -1) #Combine the momentum, eta and phi for each jet into one array\n",
    "\n",
    "print(\"There are {} outputs\".format(np.shape(bhads)[1])) # Display the number of target features the neural network will predict\n",
    "matchedtracks = matchedtracks[bjets]\n",
    "print(\"There are {} inputs\".format(np.shape(matchedtracks)[1])) # Display the number of target features the neural network will use in it's ppredictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(68143, 3)\n",
      "(5,)\n",
      "[1.48e+05, 1.04e+05, 1.16e+05, 4.03e+04, ... 8.14e+04, 9.83e+04, 1.45e+05, 9.11e+04]\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(bhads)) #Check the shape of the neural network\n",
    "print(np.shape(jet_features[:-1])) #Check for shape of the jet features\n",
    "print(jets[jet_features[0]]) # Check the jets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(68143, 3)\n"
     ]
    }
   ],
   "source": [
    "# Transform the jet and tracks to unstructed data.\n",
    "jets = structured_to_unstructured(jets[jet_features[:-3]])\n",
    "matchedtracks = structured_to_unstructured(matchedtracks)\n",
    "print(np.shape(jets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1.47e+04, 0.753, 1.14, 1.19, 75.5, ... -0.165, -0.51, -0.0283, -0.692, -0.038]]]\n",
      "(68143, 8)\n"
     ]
    }
   ],
   "source": [
    "#Check the matchtracks are the correct shape\n",
    "print(matchedtracks[:, 0:1])\n",
    "print(np.shape(matchedtracks[:, :, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(68143, 8, 3)\n",
      "(68143, 8, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17812/1222727277.py:16: RuntimeWarning: overflow encountered in sinh\n",
      "  pzs = np.where(mask1 | mask3, pts, pts * np.sinh(etas))\n"
     ]
    }
   ],
   "source": [
    "# Convert the coordinates of the b jets and tracks to cartesian coordinates\n",
    "tracks_p = pt_eta_phi_2_px_py_pz_tracks(matchedtracks.to_numpy())\n",
    "bhads = pt_eta_phi_2_px_py_pz_jets(bhads)\n",
    "\n",
    "#Check the shape of the momenta of the tracks and the rest of the data is consistent\n",
    "print(np.shape(tracks_p))\n",
    "print(np.shape(matchedtracks[:, :, 3:]))\n",
    "\n",
    "#Combine the momenta of the tracks with the rest of the track features to form the track dataset\n",
    "tracks = np.concatenate([tracks_p,matchedtracks[:,:,3:].to_numpy()],axis = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(68143, 8, 8)\n",
      "[6.20926450e+03 1.33553447e+04 1.21693980e+04 1.18753994e+00\n",
      " 7.55359192e+01 1.33110714e+00 8.57456207e+01 1.32391548e+00]\n",
      "[ 48855.56531144 128363.19160447 124938.01790683]\n"
     ]
    }
   ],
   "source": [
    "#Check that this is all the correct shape\n",
    "print(np.shape(tracks))\n",
    "print(tracks[0,0])\n",
    "print(bhads[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-18 12:10:36.332222: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-11-18 12:10:36.332254: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-11-18 12:10:36.332270: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (vonneumann.csc.warwick.ac.uk): /proc/driver/nvidia/version does not exist\n",
      "2022-11-18 12:10:36.332511: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Builds the deep neural network\n",
    "track_layers = [64, 64, 64, 64, 64, 64]\n",
    "jet_layers = [128, 128, 128, 128, 128, 128]\n",
    "DeepNet = DeepSetNeuralNetwork(\n",
    "    [len(track_features)]+track_layers, jet_layers,3, LR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a Keras model that is a mirror image of the DeepSetNeuralNetwork to tune the hyperparameters of.\n",
    "def model_builder(hp):\n",
    "    \"\"\"\n",
    "    This function lays out the Deep Set Neural Architecture\n",
    "    - A neural network is applied first to the tracks to extract information from the tracks.\n",
    "    - This information produces an ensemble space which, the outputs of which are then summed to produce\n",
    "        the inputs for the next layer\n",
    "    - A neural network is then applied to the jet data obtained from the tracks. \n",
    "        To perform current univariate regression.\n",
    "    \"\"\"\n",
    "    # Create the ranges of hyperparameters to explore\n",
    "    dropouts = hp.Choice('dropout', [0.001,0.05,0.20,0.40,0.50])\n",
    "    track_layer = hp.Choice('track_layers',[32,64,128,256,512])\n",
    "    jet_layer = hp.Choice('jet_layers',[32,64,128,256,512])\n",
    "    activation_func = hp.Choice('act_func',[\"relu\",\"elu\"])\n",
    "    Learning_rate = hp.Choice('learning_rate',[1e-6,1e-5,1e-4,1e-3,1e-2])\n",
    "\n",
    "    #Create the track and jet layers\n",
    "    track_layers = [len(track_features)]+[track_layer,track_layer,track_layer,track_layer,track_layer]\n",
    "    jet_layers = [jet_layer,jet_layer,jet_layer,jet_layer,jet_layer,jet_layer]\n",
    "\n",
    "    #Set the number of targets being explored\n",
    "    n_targets = 3\n",
    "    \n",
    "    #Follows the DeepSetNeural Architecture\n",
    "    inputs = layers.Input(shape=(None, track_layers[0]))\n",
    "    outputs = inputs\n",
    "    outputs = layers.Masking(mask_value=MASKVAL)(outputs)\n",
    "\n",
    "    counter = 0\n",
    "    for nodes in track_layers[:-1]:\n",
    "        outputs = layers.TimeDistributed(\n",
    "            layers.Dense(nodes, activation=activation_func, kernel_initializer= \"he_normal\"))(outputs)\n",
    "        if counter % 4 == 0:\n",
    "            outputs = layers.Dropout(dropouts)(outputs)\n",
    "        else:\n",
    "            counter += 1\n",
    "        outputs = layers.BatchNormalization()(outputs)\n",
    "\n",
    "    outputs = layers.TimeDistributed(layers.Dense(\n",
    "        track_layers[-1], activation='softmax'))(outputs)\n",
    "    outputs = Sum()(outputs)\n",
    "\n",
    "    counter = 0\n",
    "    for nodes in jet_layers:\n",
    "        outputs = layers.Dense(nodes, activation=activation_func, kernel_initializer= \"he_normal\")(outputs)\n",
    "        if counter % 4 == 0:\n",
    "            outputs = layers.Dropout(0.01)(outputs)\n",
    "        else:\n",
    "            counter += 1\n",
    "        outputs = layers.BatchNormalization()(outputs)\n",
    "\n",
    "    outputs = layers.Dense(n_targets+n_targets*(n_targets+1)//2)(outputs)\n",
    "\n",
    "    Model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    # Specify the neural network's optimizer and loss function\n",
    "    Model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=Learning_rate,clipnorm = 1.0),\n",
    "    loss=LogNormal_Loss_Function\n",
    "    )\n",
    "\n",
    "    return Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, None, 8)]         0         \n",
      "                                                                 \n",
      " masking (Masking)           (None, None, 8)           0         \n",
      "                                                                 \n",
      " time_distributed (TimeDistr  (None, None, 8)          72        \n",
      " ibuted)                                                         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, None, 8)           0         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, None, 8)          32        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " time_distributed_1 (TimeDis  (None, None, 64)         576       \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, None, 64)          0         \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, None, 64)         256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " time_distributed_2 (TimeDis  (None, None, 64)         4160      \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, None, 64)          0         \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, None, 64)         256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " time_distributed_3 (TimeDis  (None, None, 64)         4160      \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, None, 64)          0         \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, None, 64)         256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " time_distributed_4 (TimeDis  (None, None, 64)         4160      \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, None, 64)          0         \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, None, 64)         256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " time_distributed_5 (TimeDis  (None, None, 64)         4160      \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, None, 64)          0         \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, None, 64)         256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " time_distributed_6 (TimeDis  (None, None, 64)         4160      \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " sum (Sum)                   (None, 64)                0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 128)               8320      \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 128)              512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 128)              512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 128)              512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 128)              512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 128)              512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " batch_normalization_11 (Bat  (None, 128)              512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 9)                 1161      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 117,873\n",
      "Trainable params: 115,681\n",
      "Non-trainable params: 2,192\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Summarises the Neural Network Architecture\n",
    "DeepNet.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and validation sets.\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    tracks, bhads, train_size=0.7, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47700, 8, 8) (47700, 3)\n"
     ]
    }
   ],
   "source": [
    "#Check for the of the training and validation sets\n",
    "print(np.shape(X_train), np.shape(y_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introduce early_stopping to prevent overfitting\n",
    "early_stopping = callbacks.EarlyStopping(\n",
    "    min_delta=0.001,  # The minimum amount of change to count as an improvement\n",
    "    patience=20,  # The number of epochs to wait before stopping\n",
    "    restore_best_weights=True,  # Keep the best weights\n",
    ")\n",
    "# Prevent spikes in the validation and training loss due to the gradient descent kicking the network out of a local minima\n",
    "reduce_learn_on_plateau = callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss', factor=0.8, patience=10, min_lr=1e-6)\n",
    "\n",
    "# Save the weights of the model to allow reuse in future.\n",
    "path = \"/home/physics/phujdj/DeepLearningParticlePhysics/CheckPoints/DeepNetWeights&Biases-{epoch:04d}.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(path)\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=path,\n",
    "                                                 save_weights_only=True, verbose=0, save_best_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1491/1491 [==============================] - 13s 6ms/step - loss: 34682830848.0000 - val_loss: 1172928128.0000 - lr: 1.0000e-04\n",
      "Epoch 2/1000\n",
      "1491/1491 [==============================] - 9s 6ms/step - loss: 224249104.0000 - val_loss: 1151268.6250 - lr: 1.0000e-04\n",
      "Epoch 3/1000\n",
      "1491/1491 [==============================] - 9s 6ms/step - loss: 62801.3281 - val_loss: 35.9062 - lr: 1.0000e-04\n",
      "Epoch 4/1000\n",
      "1491/1491 [==============================] - 8s 6ms/step - loss: 35.6293 - val_loss: 35.7847 - lr: 1.0000e-04\n",
      "Epoch 5/1000\n",
      "1491/1491 [==============================] - 9s 6ms/step - loss: 35.4560 - val_loss: 35.5294 - lr: 1.0000e-04\n",
      "Epoch 6/1000\n",
      "1491/1491 [==============================] - 8s 6ms/step - loss: 35.6007 - val_loss: 34.8613 - lr: 1.0000e-04\n",
      "Epoch 7/1000\n",
      "1491/1491 [==============================] - 8s 6ms/step - loss: 35.2616 - val_loss: 35.7822 - lr: 1.0000e-04\n",
      "Epoch 8/1000\n",
      "1491/1491 [==============================] - 8s 6ms/step - loss: 35.1702 - val_loss: 35.7439 - lr: 1.0000e-04\n",
      "Epoch 9/1000\n",
      "1491/1491 [==============================] - 9s 6ms/step - loss: 35.1119 - val_loss: 35.8825 - lr: 1.0000e-04\n",
      "Epoch 10/1000\n",
      "1491/1491 [==============================] - 9s 6ms/step - loss: 35.0666 - val_loss: 35.2787 - lr: 1.0000e-04\n",
      "Epoch 11/1000\n",
      "1491/1491 [==============================] - 9s 6ms/step - loss: 35.0148 - val_loss: 35.3961 - lr: 1.0000e-04\n",
      "Epoch 12/1000\n",
      "1491/1491 [==============================] - 9s 6ms/step - loss: 34.9988 - val_loss: 36.3243 - lr: 1.0000e-04\n",
      "Epoch 13/1000\n",
      "1491/1491 [==============================] - 9s 6ms/step - loss: 34.9580 - val_loss: 35.0876 - lr: 1.0000e-04\n",
      "Epoch 14/1000\n",
      "1491/1491 [==============================] - 9s 6ms/step - loss: 34.9179 - val_loss: 35.8464 - lr: 1.0000e-04\n",
      "Epoch 15/1000\n",
      "1491/1491 [==============================] - 9s 6ms/step - loss: 34.9141 - val_loss: 37.1967 - lr: 1.0000e-04\n",
      "Epoch 16/1000\n",
      "1491/1491 [==============================] - 9s 6ms/step - loss: 34.8848 - val_loss: 34.8688 - lr: 1.0000e-04\n",
      "Epoch 17/1000\n",
      "1491/1491 [==============================] - 9s 6ms/step - loss: 34.8654 - val_loss: 34.8378 - lr: 8.0000e-05\n",
      "Epoch 18/1000\n",
      "1491/1491 [==============================] - 9s 6ms/step - loss: 34.8613 - val_loss: 35.9834 - lr: 8.0000e-05\n",
      "Epoch 19/1000\n",
      "1491/1491 [==============================] - 9s 6ms/step - loss: 34.8437 - val_loss: 37.5117 - lr: 8.0000e-05\n",
      "Epoch 20/1000\n",
      "1491/1491 [==============================] - 9s 6ms/step - loss: 34.8362 - val_loss: 34.7773 - lr: 8.0000e-05\n",
      "Epoch 21/1000\n",
      "1491/1491 [==============================] - 9s 6ms/step - loss: 34.8216 - val_loss: 34.7710 - lr: 8.0000e-05\n",
      "Epoch 22/1000\n",
      "1491/1491 [==============================] - 9s 6ms/step - loss: 34.8177 - val_loss: 35.3610 - lr: 8.0000e-05\n",
      "Epoch 23/1000\n",
      "1491/1491 [==============================] - 9s 6ms/step - loss: 34.8088 - val_loss: 37.0976 - lr: 8.0000e-05\n",
      "Epoch 24/1000\n",
      "1491/1491 [==============================] - 8s 6ms/step - loss: 34.7857 - val_loss: 36.6220 - lr: 8.0000e-05\n",
      "Epoch 25/1000\n",
      "1491/1491 [==============================] - 9s 6ms/step - loss: 34.7814 - val_loss: 40.2904 - lr: 8.0000e-05\n",
      "Epoch 26/1000\n",
      "1491/1491 [==============================] - 9s 6ms/step - loss: 34.7619 - val_loss: 35.1154 - lr: 8.0000e-05\n",
      "Epoch 27/1000\n",
      "1491/1491 [==============================] - 9s 6ms/step - loss: 34.7541 - val_loss: 35.1110 - lr: 8.0000e-05\n",
      "Epoch 28/1000\n",
      "1491/1491 [==============================] - 9s 6ms/step - loss: 34.7528 - val_loss: 35.0951 - lr: 8.0000e-05\n",
      "Epoch 29/1000\n",
      "1491/1491 [==============================] - 9s 6ms/step - loss: 34.7474 - val_loss: 37.3407 - lr: 8.0000e-05\n",
      "Epoch 30/1000\n",
      "1491/1491 [==============================] - 9s 6ms/step - loss: 34.7436 - val_loss: 34.6586 - lr: 8.0000e-05\n",
      "Epoch 31/1000\n",
      "1491/1491 [==============================] - 9s 6ms/step - loss: 34.7293 - val_loss: 34.9315 - lr: 8.0000e-05\n",
      "Epoch 32/1000\n",
      "1491/1491 [==============================] - 9s 6ms/step - loss: 34.7235 - val_loss: 35.1685 - lr: 8.0000e-05\n",
      "Epoch 33/1000\n",
      "1491/1491 [==============================] - 9s 6ms/step - loss: 34.7158 - val_loss: 35.9107 - lr: 8.0000e-05\n",
      "Epoch 34/1000\n",
      "1491/1491 [==============================] - 9s 6ms/step - loss: 34.7122 - val_loss: 34.9744 - lr: 8.0000e-05\n",
      "Epoch 35/1000\n",
      "1491/1491 [==============================] - 9s 6ms/step - loss: 34.7048 - val_loss: 36.7609 - lr: 8.0000e-05\n",
      "Epoch 36/1000\n",
      "1491/1491 [==============================] - 9s 6ms/step - loss: 34.6886 - val_loss: 35.5481 - lr: 8.0000e-05\n",
      "Epoch 37/1000\n",
      "1491/1491 [==============================] - 9s 6ms/step - loss: 34.7038 - val_loss: 35.3708 - lr: 8.0000e-05\n",
      "Epoch 38/1000\n",
      "1491/1491 [==============================] - 9s 6ms/step - loss: 34.6785 - val_loss: 35.3499 - lr: 8.0000e-05\n",
      "Epoch 39/1000\n",
      "1491/1491 [==============================] - 9s 6ms/step - loss: 34.6948 - val_loss: 35.4950 - lr: 8.0000e-05\n",
      "Epoch 40/1000\n",
      "1491/1491 [==============================] - 9s 6ms/step - loss: 34.6781 - val_loss: 35.4649 - lr: 8.0000e-05\n",
      "Epoch 41/1000\n",
      "1491/1491 [==============================] - 9s 6ms/step - loss: 34.7139 - val_loss: 38.9548 - lr: 6.4000e-05\n",
      "Epoch 42/1000\n",
      "1491/1491 [==============================] - 9s 6ms/step - loss: 34.6856 - val_loss: 35.6127 - lr: 6.4000e-05\n",
      "Epoch 43/1000\n",
      "1491/1491 [==============================] - 9s 6ms/step - loss: 34.6819 - val_loss: 34.6847 - lr: 6.4000e-05\n",
      "Epoch 44/1000\n",
      "1491/1491 [==============================] - 9s 6ms/step - loss: 34.6533 - val_loss: 34.6854 - lr: 6.4000e-05\n",
      "Epoch 45/1000\n",
      "1491/1491 [==============================] - 9s 6ms/step - loss: 34.6686 - val_loss: 34.6322 - lr: 6.4000e-05\n",
      "Epoch 46/1000\n",
      "1491/1491 [==============================] - 9s 6ms/step - loss: 34.6478 - val_loss: 41.9210 - lr: 6.4000e-05\n",
      "Epoch 47/1000\n",
      "1491/1491 [==============================] - 9s 6ms/step - loss: 34.6421 - val_loss: 35.4101 - lr: 6.4000e-05\n",
      "Epoch 48/1000\n",
      "1491/1491 [==============================] - 9s 6ms/step - loss: 34.6381 - val_loss: 35.3193 - lr: 6.4000e-05\n",
      "Epoch 49/1000\n",
      "1491/1491 [==============================] - 9s 6ms/step - loss: 34.6365 - val_loss: 36.1742 - lr: 6.4000e-05\n",
      "Epoch 50/1000\n",
      "1491/1491 [==============================] - 9s 6ms/step - loss: 34.6367 - val_loss: 38.9141 - lr: 6.4000e-05\n",
      "Epoch 51/1000\n",
      "1491/1491 [==============================] - 9s 6ms/step - loss: 34.6456 - val_loss: 40.2968 - lr: 6.4000e-05\n",
      "Epoch 52/1000\n",
      "1491/1491 [==============================] - 9s 6ms/step - loss: 34.6397 - val_loss: 35.8829 - lr: 6.4000e-05\n",
      "Epoch 53/1000\n",
      "1491/1491 [==============================] - 9s 6ms/step - loss: 34.6325 - val_loss: 35.4965 - lr: 6.4000e-05\n",
      "Epoch 54/1000\n",
      "1491/1491 [==============================] - 9s 6ms/step - loss: 34.6267 - val_loss: 34.9024 - lr: 6.4000e-05\n",
      "Epoch 55/1000\n",
      "1491/1491 [==============================] - 9s 6ms/step - loss: 34.6350 - val_loss: 36.1144 - lr: 6.4000e-05\n",
      "Epoch 56/1000\n",
      "1491/1491 [==============================] - 9s 6ms/step - loss: 34.6257 - val_loss: 35.0874 - lr: 5.1200e-05\n",
      "Epoch 57/1000\n",
      "1491/1491 [==============================] - 9s 6ms/step - loss: 34.6152 - val_loss: 37.0297 - lr: 5.1200e-05\n",
      "Epoch 58/1000\n",
      "1491/1491 [==============================] - 9s 6ms/step - loss: 34.6048 - val_loss: 35.9215 - lr: 5.1200e-05\n",
      "Epoch 59/1000\n",
      "1491/1491 [==============================] - 9s 6ms/step - loss: 34.6705 - val_loss: 41.6339 - lr: 5.1200e-05\n",
      "Epoch 60/1000\n",
      "1491/1491 [==============================] - 9s 6ms/step - loss: 34.6046 - val_loss: 36.9112 - lr: 5.1200e-05\n",
      "Epoch 61/1000\n",
      "1491/1491 [==============================] - 9s 6ms/step - loss: 34.6270 - val_loss: 35.5107 - lr: 5.1200e-05\n",
      "Epoch 62/1000\n",
      "1491/1491 [==============================] - 9s 6ms/step - loss: 34.6007 - val_loss: 34.6579 - lr: 5.1200e-05\n",
      "Epoch 63/1000\n",
      "1491/1491 [==============================] - 9s 6ms/step - loss: 34.6051 - val_loss: 35.3467 - lr: 5.1200e-05\n",
      "Epoch 64/1000\n",
      "1491/1491 [==============================] - 9s 6ms/step - loss: 34.5969 - val_loss: 34.9317 - lr: 5.1200e-05\n",
      "Epoch 65/1000\n",
      "1491/1491 [==============================] - 9s 6ms/step - loss: 34.5922 - val_loss: 40.4809 - lr: 5.1200e-05\n"
     ]
    }
   ],
   "source": [
    "# Train the neural network\n",
    "history = DeepNet.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    batch_size=BATCHSIZE,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[early_stopping, reduce_learn_on_plateau,\n",
    "               cp_callback]  # Enter call back\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss and validation curves vs epoch\n",
    "history_df = pd.DataFrame(history.history)\n",
    "np.log(history_df.loc[:, [\"loss\", \"val_loss\"]]).plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2130/2130 [==============================] - 3s 1ms/step\n",
      "[[ 2.23265152e+01  5.66946373e+01  2.79504716e-01  1.07514963e+01\n",
      "   1.09271622e+01  1.19079762e+01  7.21378028e-02  1.84065536e-01\n",
      "   8.54414165e-01]\n",
      " [-6.64195709e+01 -7.19502106e+01  3.82595978e+01  1.07038193e+01\n",
      "   1.12217703e+01  1.24223518e+01  8.09958637e-01  1.07637219e-01\n",
      "   3.41384292e+00]\n",
      " [ 2.36094723e+01 -4.51908607e+01 -7.43504868e+01  1.09630270e+01\n",
      "   1.09140368e+01  1.28425274e+01  9.40134048e-01 -2.41652191e-01\n",
      "   3.12981033e+00]\n",
      " [ 3.47411995e+01 -3.18854828e+01 -3.47008858e+01  1.03978806e+01\n",
      "   1.07678232e+01  1.08860378e+01 -5.60446501e-01  4.48947281e-01\n",
      "  -8.85602832e-01]\n",
      " [ 4.02164955e+01 -4.33705254e+01 -3.18382778e+01  1.07025290e+01\n",
      "   1.09164705e+01  1.11048279e+01 -5.29282093e-01  1.84754223e-01\n",
      "  -9.04503107e-01]\n",
      " [-6.47926998e+00  5.07267723e+01 -1.04292469e+01  1.05622177e+01\n",
      "   1.11976576e+01  1.11567516e+01 -2.55458176e-01  4.82984185e-01\n",
      "   1.54380482e-02]\n",
      " [-2.57061119e+01 -3.13163319e+01  1.29543219e+01  1.08022032e+01\n",
      "   1.11156044e+01  1.24304695e+01  1.43660277e-01  2.21524790e-01\n",
      "   1.76377189e+00]\n",
      " [ 1.27610407e+01 -2.80471973e+01 -5.15321770e+01  1.07014246e+01\n",
      "   1.09912567e+01  1.17367477e+01 -2.22624600e-01  7.92506635e-01\n",
      "  -7.39525408e-02]\n",
      " [ 5.95931473e+01 -1.36826096e+01 -2.47297859e+01  1.10510054e+01\n",
      "   1.00717239e+01  1.09438000e+01 -1.15943123e-02  1.39218390e-01\n",
      "  -9.54836547e-01]\n",
      " [ 9.77483749e+00  7.56426010e+01  1.21245174e+01  1.11290340e+01\n",
      "   1.12947788e+01  1.15032864e+01 -5.81241548e-01 -2.32051432e-01\n",
      "   1.32014394e-01]]\n"
     ]
    }
   ],
   "source": [
    "# Have the model predict the total momentum of the b tracks\n",
    "predictions = DeepNet.predict(tracks)\n",
    "# Output the first 10 guesses\n",
    "print(predictions[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum validation loss: 34.632205963134766\n"
     ]
    }
   ],
   "source": [
    "# Output to the console the minimum epoch\n",
    "print(\"Minimum validation loss: {}\".format(history_df[\"val_loss\"].min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68143 68143\n",
      "(68143, 9)\n"
     ]
    }
   ],
   "source": [
    "# Ensure the dimensions are correct\n",
    "print(len(tracks), len(predictions))\n",
    "print(np.shape(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-449.26678 148.72632\n",
      "Minimum and maximum values\n",
      "The min/max of bhad momenta:  -2273167.0883596055 1827356.5267840482\n",
      "The min/max of the ppred - ptrue -777768.7593189306 467778.248348503\n",
      "The min/max of the pull -8.837223442626076 6.256611672050029\n",
      "Median and IQR\n",
      "The Median/IQR for the ppred - ptrue:  391.57437455949844 91179.64565455745\n",
      "The Median/IQR for the pull  0.022520383651363374 1.9038276078766736\n",
      "Mean and standard deviation\n",
      "The mean/std for the ppred - ptrue:  52.70477503898669 65389.3419779312\n",
      "The mean/std for the pull -0.12496589914425724 1.1445492686986536\n"
     ]
    }
   ],
   "source": [
    "# Create the distribution of errors to access the performance of the neural network\n",
    "pull = (predictions[:, 1] - bhads[:,1])\n",
    "scaled_pull = pull/np.exp(predictions[:, 4])\n",
    "# Compare and constrast the true and predicted momentums\n",
    "print(np.min(predictions[:,1]),np.max(predictions[:,1]))\n",
    "\n",
    "print(\"Minimum and maximum values\")\n",
    "print(\"The min/max of bhad momenta: \", np.min(bhads), np.max(bhads))\n",
    "print(\"The min/max of the ppred - ptrue\", np.min(pull), np.max(pull))\n",
    "print(\"The min/max of the pull\", np.min(scaled_pull), np.max(scaled_pull))\n",
    "\n",
    "print(\"Median and IQR\")\n",
    "print(\"The Median/IQR for the ppred - ptrue: \", np.median(pull),\n",
    "      np.percentile(pull, 75)-np.percentile(pull, 25))\n",
    "print(\"The Median/IQR for the pull \", np.median(scaled_pull),\n",
    "      np.percentile(scaled_pull, 75)-np.percentile(scaled_pull, 25))\n",
    "\n",
    "print(\"Mean and standard deviation\")\n",
    "print(\"The mean/std for the ppred - ptrue: \", np.mean(pull), np.std(pull))\n",
    "print(\"The mean/std for the pull\", np.mean(scaled_pull), np.std(scaled_pull))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Plot the distribution of error\n",
    "fig = binneddensity(pull, fixedbinning(-3e5, 3e5, 100),\n",
    "                    xlabel=\"ptpred - pttrue [MeV]\")\n",
    "fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Plot the distribution of the pull values\n",
    "fig = binneddensity(scaled_pull, fixedbinning(-4.0, 4.0, 100), xlabel=\"pull\")\n",
    "fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 352ms/step\n",
      "[[-66.41957    -71.95021     38.259598    10.703819    11.22177\n",
      "   12.422352     0.80995864   0.10763722   3.413843  ]]\n",
      "[   843.45625286  77133.74792279 179693.16123271]\n",
      "1/1 [==============================] - 0s 20ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=35.143463>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predict the momentas for a single jet and determine the loss\n",
    "print(DeepNet.predict(tracks[1]))\n",
    "print(bhads[1])\n",
    "\n",
    "LogNormal_Loss_Function_Check(bhads[1],DeepNet.predict(tracks[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2130/2130 - 2s - loss: 34.6364 - 2s/epoch - 1ms/step\n",
      "The Loaded DeepNet has loss:  34.636\n"
     ]
    }
   ],
   "source": [
    "#Evaluate the entire performance of the model\n",
    "loss = DeepNet.evaluate(tracks,bhads,verbose = 2)\n",
    "print(\"The Loaded DeepNet has loss: \", round(loss,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up the hyperparameter\n",
    "SEED = tf.random.set_seed(42) # Generate a random seed\n",
    "max_trials = 10\n",
    "tuner = kt.RandomSearch(model_builder,\n",
    "                        objective='val_loss',\n",
    "                        seed=SEED,\n",
    "                        overwrite=True,\n",
    "                        max_trials=15,\n",
    "                        directory='/home/physics/phujdj/DeepLearningParticlePhysics',\n",
    "                        project_name=\"DeepSetHyperTraining\",\n",
    "                        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create an early stoping to properly survey the values\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 15 Complete [00h 03m 16s]\n",
      "val_loss: 35.309566497802734\n",
      "\n",
      "Best val_loss So Far: 34.592384338378906\n",
      "Total elapsed time: 00h 39m 40s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "#Search the parameter space to obtain the best hyperparameter values\n",
    "tuner.search(X_train, y_train, validation_data=(\n",
    "    X_valid, y_valid), epochs=20, callbacks=[stop_early])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The hyperparameter search is complete. The optimal number of track layers is 512, the optimal number of jet layers is 128, the optimal learning rate for the optimizer\n",
      "is 0.0001, the optimal dropout rate is 0.05 and finally the optimal activation function is elu\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_hps = tuner.get_best_hyperparameters(num_trials=10)[0]\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete. The optimal number of track layers is {best_hps.get('track_layers')}, the optimal number of jet layers is {best_hps.get('jet_layers')}, the optimal learning rate for the optimizer\n",
    "is {best_hps.get('learning_rate')}, the optimal dropout rate is {best_hps.get('dropout')} and finally the optimal activation function is {best_hps.get('act_func')}\n",
    "\"\"\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "a05ddcd8ffea9a6a7d2e914b733df5445b717626b5b8c92c04bfc4eb6e7f5cba"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
